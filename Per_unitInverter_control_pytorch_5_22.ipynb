{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/halduaij/inverter/blob/main/Per_unitInverter_control_pytorch_5_22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9blFeXYmWLyW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5w9pjYZSDll"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import fsolve, root, least_squares, newton_krylov\n",
        "\n",
        "def super_safe_solve(F, x0,\n",
        "                     jac=None,\n",
        "                     scale=None,\n",
        "                     tol=1e-8,\n",
        "                     maxfev=40000,\n",
        "                     methods=(\"fsolve\",\"hybr\",\"trf\",\"krylov\"),\n",
        "                     n_multistart=3,\n",
        "                     multistart_radius=1e-1):\n",
        "    \"\"\"\n",
        "    Try many root‐finding strategies in turn, with optional scaling\n",
        "    and multi‐start.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    F      : callable F(x) -> shape (n,)\n",
        "    x0     : initial guess array, shape (n,)\n",
        "    jac    : callable J(x)->(n,n) or None\n",
        "    scale  : array of length n for variable scaling, or None\n",
        "    tol    : required residual norm\n",
        "    maxfev : max function evals for fsolve / least_squares\n",
        "    methods: tuple of methods to try in order:\n",
        "             'fsolve' -> scipy.optimize.fsolve\n",
        "             'hybr'   -> scipy.optimize.root(method='hybr')\n",
        "             'trf'    -> scipy.optimize.least_squares(method='trf')\n",
        "             'krylov' -> scipy.optimize.newton_krylov\n",
        "    n_multistart : how many random starting points if all methods fail\n",
        "    multistart_radius : spread for random restarts around x0\n",
        "    \"\"\"\n",
        "    # 1) handle scaling\n",
        "    if scale is None:\n",
        "        scale = np.ones_like(x0)\n",
        "    invscale = 1.0/scale\n",
        "\n",
        "    def G(u):\n",
        "        x = invscale * u\n",
        "        return scale * F(x)\n",
        "\n",
        "    def g_jac(u):\n",
        "        x = invscale * u\n",
        "        Jx = jac(x)\n",
        "        # chain‐rule: dG/du = scale * Jx * diag(invscale)\n",
        "        return (scale[:,None] * Jx) * invscale[None,:]\n",
        "\n",
        "    # helper to test solution\n",
        "    def test_solution(x):\n",
        "        res = np.linalg.norm(F(x))\n",
        "        return res < tol, res\n",
        "\n",
        "    # 2) try each method once\n",
        "    for method in methods:\n",
        "        try:\n",
        "            if method == \"fsolve\":\n",
        "                sol, info, ier, msg = fsolve(\n",
        "                    G, scale*x0,\n",
        "                    fprime=(g_jac if jac else None),\n",
        "                    full_output=True,\n",
        "                    maxfev=maxfev\n",
        "                )\n",
        "                x_hat = invscale * sol\n",
        "                ok, res = test_solution(x_hat)\n",
        "\n",
        "            elif method == \"hybr\":\n",
        "                out = root(G, scale*x0, jac=(g_jac if jac else None),\n",
        "                           method=\"hybr\", options={\"maxfev\": maxfev})\n",
        "                x_hat = invscale * out.x\n",
        "                ok, res = (out.success, np.linalg.norm(F(x_hat)))\n",
        "\n",
        "            elif method == \"trf\":\n",
        "                out = least_squares(\n",
        "                    G, scale*x0,\n",
        "                    jac=(g_jac if jac else '2-point'),\n",
        "                    ftol=tol, xtol=tol,\n",
        "                    max_nfev=maxfev,\n",
        "                    method=\"trf\"\n",
        "                )\n",
        "                x_hat = invscale * out.x\n",
        "                ok, res = (out.success, np.linalg.norm(F(x_hat)))\n",
        "\n",
        "            elif method == \"krylov\":\n",
        "                sol = newton_krylov(G, scale*x0, f_tol=tol, maxiter=100)\n",
        "                x_hat = invscale * sol\n",
        "                ok, res = test_solution(x_hat)\n",
        "\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if ok:\n",
        "                return x_hat, True, res, f\"Converged with {method}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            # ignore and try next\n",
        "            pass\n",
        "\n",
        "    # 3) multi‑start around x0\n",
        "    for i in range(n_multistart):\n",
        "        x0p = x0 + multistart_radius * np.random.randn(*x0.shape)\n",
        "        try:\n",
        "            sol, info, ier, msg = fsolve(\n",
        "                G, scale*x0p,\n",
        "                fprime=(g_jac if jac else None),\n",
        "                full_output=True,\n",
        "                maxfev=maxfev\n",
        "            )\n",
        "            x_hat = invscale * sol\n",
        "            ok, res = test_solution(x_hat)\n",
        "            if ok:\n",
        "                return x_hat, True, res, f\"Converged with fsolve after {i+1} restarts\"\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # 4) give up\n",
        "    return None, False, None, \"All methods failed to converge\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAsuLncx1aqz",
        "outputId": "d6e427fe-bbcf-4589-86d5-5d380dc1bb4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SaLSa-Optimizer in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from SaLSa-Optimizer) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from SaLSa-Optimizer) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->SaLSa-Optimizer) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->SaLSa-Optimizer) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->SaLSa-Optimizer) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install SaLSa-Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTHie0y13HkH"
      },
      "outputs": [],
      "source": [
        "from salsa.SaLSA import SaLSA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX0I_PfiSLEh"
      },
      "outputs": [],
      "source": [
        "# pcgrad.py  (stand‑alone, MIT licence)\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "class PCGrad(Optimizer):\n",
        "    \"\"\"Projection Conflicting Gradients (Yu et al., NeurIPS 2020).\n",
        "    Wrap any torch Optimizer   →  same API plus .pc_backward(loss_list).\"\"\"\n",
        "\n",
        "    def __init__(self, optimizer: Optimizer):\n",
        "        self._optim = optimizer\n",
        "        self.param_groups = self._optim.param_groups\n",
        "        self.defaults     = self._optim.defaults\n",
        "        self.state        = self._optim.state\n",
        "\n",
        "    # --- thin pass‑throughs --------------------------------------------\n",
        "    def zero_grad(self, *a, **kw): return self._optim.zero_grad(*a, **kw)\n",
        "    def step     (self, *a, **kw): return self._optim.step(*a, **kw)\n",
        "\n",
        "    # --- helpers -------------------------------------------------------\n",
        "    def _flat_grads(self):\n",
        "        return [p.grad.detach().clone() if p.grad is not None else None\n",
        "                for g in self.param_groups for p in g['params']]\n",
        "\n",
        "    def _write_grads(self, new):\n",
        "        k = 0\n",
        "        for g in self.param_groups:\n",
        "            for p in g['params']:\n",
        "                p.grad = None if new[k] is None else new[k]\n",
        "                k += 1\n",
        "\n",
        "    # --- core ----------------------------------------------------------\n",
        "    @torch.no_grad()\n",
        "    def pc_backward(self, losses, retain_graph=False):\n",
        "        if not isinstance(losses, (list, tuple)):\n",
        "            losses = [losses]\n",
        "\n",
        "        # collect gradients for each loss\n",
        "        task_grads = []\n",
        "        for i, L in enumerate(losses):\n",
        "            L.backward(retain_graph=(i < len(losses)-1) or retain_graph)\n",
        "            task_grads.append(self._flat_grads())\n",
        "            self.zero_grad(set_to_none=True)\n",
        "\n",
        "        # project pairwise conflicts\n",
        "        n_tasks, n_params = len(task_grads), len(task_grads[0])\n",
        "        merged = [torch.zeros_like(g) if g is not None else None\n",
        "                  for g in task_grads[0]]\n",
        "\n",
        "        for t in range(n_tasks):\n",
        "            g_t = task_grads[t]\n",
        "            for p in range(n_params):\n",
        "                if g_t[p] is None: continue\n",
        "                v = g_t[p].clone()\n",
        "                for s in range(n_tasks):\n",
        "                    if s == t or task_grads[s][p] is None: continue\n",
        "                    g_s = task_grads[s][p]\n",
        "                    dot = torch.dot(v.view(-1), g_s.view(-1))\n",
        "                    if dot < 0:\n",
        "                        v -= dot / (g_s.view(-1).pow(2).sum() + 1e-12) * g_s\n",
        "                merged[p] = merged[p] + v / n_tasks\n",
        "\n",
        "        self._write_grads(merged)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQTrJWVaSRTU",
        "outputId": "aeffb909-4651-437d-863c-8c9674aee890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/halduaij/torchdiffeq.git\n",
            "  Cloning https://github.com/halduaij/torchdiffeq.git to /tmp/pip-req-build-gxcbgndf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/halduaij/torchdiffeq.git /tmp/pip-req-build-gxcbgndf\n",
            "  Resolved https://github.com/halduaij/torchdiffeq.git to commit 6f4c3a4eab4b2ce54a1f7d818c72ac751e6f2c27\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq==0.2.5) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq==0.2.5) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.4.0->torchdiffeq==0.2.5) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq==0.2.5) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq==0.2.5) (3.0.2)\n",
            "Building wheels for collected packages: torchdiffeq\n",
            "  Building wheel for torchdiffeq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchdiffeq: filename=torchdiffeq-0.2.5-py3-none-any.whl size=40285 sha256=eb047f85868edd90daee680aa972431b33452e5b10bf6f21a68fc3b07c74f9bb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4ynplnjr/wheels/d7/12/81/4236755e2a66937fd6cc279fcd3b7519c8a9a67201794e04f0\n",
            "Successfully built torchdiffeq\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/halduaij/torchdiffeq.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/pollycoder/torchdiffeq.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXgtGm8rGxpZ",
        "outputId": "b1e9cc7e-0030-41bd-ee95-ec2f579c00b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/pollycoder/torchdiffeq.git\n",
            "  Cloning https://github.com/pollycoder/torchdiffeq.git to /tmp/pip-req-build-quvxc89a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pollycoder/torchdiffeq.git /tmp/pip-req-build-quvxc89a\n",
            "  Resolved https://github.com/pollycoder/torchdiffeq.git to commit 8f801446591f22bcef89012b8019a4e8f568292b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq==0.2.5) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq==0.2.5) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.4.0->torchdiffeq==0.2.5) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq==0.2.5) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq==0.2.5) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq==0.2.5) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQxF_ZtduF8w"
      },
      "outputs": [],
      "source": [
        "from torch.optim import LBFGS          # already in torch>=1.9\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z68QKDkJSAS9",
        "outputId": "44c6d2fd-3eb3-449a-bf5b-a58ea9fd2951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-4b3f6ce6977d>:717: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.original_rL           = torch.tensor(self.network.rL.clone().detach(),dtype=self.dtype, device=self.device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running multi-scenario optimization...\n",
            "Using scenario weights (for logging only): {'load_change': 1.0}\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Calculating default equilibrium target …\n",
            "Converged with trf\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 88.40486084 -84.73771882  91.91036255 -67.04908603  88.34530162\n",
            " -84.94613641]…\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchdiffeq import odeint_adjoint\n",
        "from dataclasses import dataclass\n",
        "from scipy.integrate import solve_ivp\n",
        "from torchdiffeq._impl.solvers import AdaptiveStepsizeODESolver\n",
        "from torchdiffeq._impl.misc import _handle_unused_kwargs\n",
        "from torch import Tensor\n",
        "from typing import Tuple, Optional, Callable, Dict, Any, Union # Added Union here\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "from scipy.optimize import fsolve\n",
        "import numpy as np\n",
        "from torchdiffeq import odeint\n",
        "class ShapeDebugger:\n",
        "    @staticmethod\n",
        "    def print_shape(tensor, name, full_info=False):\n",
        "        print(f\"{name}:\")\n",
        "        print(f\"  shape: {tensor.shape}\")\n",
        "        print(f\"  requires_grad: {tensor.requires_grad}\")\n",
        "        if full_info:\n",
        "            print(f\"  grad_fn: {tensor.grad_fn}\")\n",
        "            print(f\"  dtype: {tensor.dtype}\")\n",
        "            print(f\"  device: {tensor.device}\")\n",
        "        print(\"---\")\n",
        "\n",
        "@dataclass\n",
        "class Setpoints:\n",
        "    \"\"\"\n",
        "    System setpoints for power system operation.\n",
        "    All values in SI units (V, W, VAr, rad).\n",
        "    \"\"\"\n",
        "    v_star: torch.Tensor  # Voltage magnitude setpoints [Nc]\n",
        "    p_star: torch.Tensor  # Active power setpoints [Nc]\n",
        "    q_star: torch.Tensor  # Reactive power setpoints [Nc]\n",
        "    theta_star: torch.Tensor  # Relative voltage angles (for tracking only in αβ) [Nc]\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# PowerSystemNetwork in PyTorch\n",
        "##############################################################################\n",
        "class PowerSystemNetwork:\n",
        "    \"\"\"\n",
        "    Power system network model implementing equations 17-18 from your reference.\n",
        "    Handles network topology, line dynamics, and current calculations.\n",
        "    \"\"\"\n",
        "    def __init__(self, device='cuda', dtype=torch.float64):\n",
        "        self.device = device\n",
        "        self.dtype = dtype\n",
        "\n",
        "        # Base values (Section VII)\n",
        "        self.Sb = 1000.0                # Base power: 1 kW\n",
        "        self.Vb = 120.0                 # Base voltage: 120 V\n",
        "        self.omega0 = 2.0 * math.pi * 60.0  # Nominal frequency: 60 Hz\n",
        "\n",
        "        # Network size (Figure 6)\n",
        "        self.Nc = 3   # Number of converters\n",
        "        self.Nt = 3   # Number of transmission lines\n",
        "        self.n = 2    # αβ dimension\n",
        "\n",
        "        # Network parameters (Table I)\n",
        "        self.rt = 0.05            # Line resistance (50 mΩ)\n",
        "        self.lt = 0.2e-3         # Line inductance (0.2 mH)\n",
        "\n",
        "        # Load resistance at common coupling point\n",
        "        self.rL =  115.0*1\n",
        "        self.kappa = math.atan(self.omega0 * self.lt / self.rt)\n",
        "\n",
        "        # R(κ) base\n",
        "        R_kappa_base = torch.tensor([\n",
        "            [math.cos(self.kappa), -math.sin(self.kappa)],\n",
        "            [math.sin(self.kappa),  math.cos(self.kappa)]\n",
        "        ], dtype=self.dtype, device=self.device)\n",
        "\n",
        "        # Full R_kappa: extend to Nc converters using Kronecker product\n",
        "        self.R_kappa = torch.kron(\n",
        "            torch.eye(self.Nc, dtype=self.dtype, device=self.device),\n",
        "            R_kappa_base\n",
        "        )\n",
        "\n",
        "        # Breaker status tracking\n",
        "        self.breaker_status = torch.ones(self.Nc, dtype=torch.bool, device=self.device)\n",
        "\n",
        "        # Identity, rotation J, etc.\n",
        "        self.J = torch.tensor([[0.0, -1.0], [1.0, 0.0]], dtype=self.dtype, device=self.device)\n",
        "        self.In = torch.eye(self.n, dtype=self.dtype, device=self.device)\n",
        "\n",
        "        # Initialize network\n",
        "        self.setup_network()\n",
        "\n",
        "    def setup_network(self):\n",
        "        \"\"\"Setup all network matrices in αβ frame.\"\"\"\n",
        "        # Network topology from Figure 6 - radial connection to common point\n",
        "        B_lines_np = [\n",
        "            [1.0, 0.0, 0.0],  # Conv 1 -> line 1\n",
        "            [0.0, 1.0, 0.0],  # Conv 2 -> line 2\n",
        "            [0.0, 0.0, 1.0]   # Conv 3 -> line 3\n",
        "        ]\n",
        "        # Convert to torch\n",
        "        self.B_lines = torch.tensor(\n",
        "            B_lines_np, dtype=self.dtype, device=self.device\n",
        "        )\n",
        "        # Extended incidence matrix\n",
        "        self.B = torch.kron(self.B_lines, self.In)\n",
        "\n",
        "        # Transmission line matrices\n",
        "        self.Lt = torch.kron(\n",
        "            torch.eye(self.Nt, dtype=self.dtype, device=self.device),\n",
        "            self.lt * self.In\n",
        "        )\n",
        "        self.Rt = torch.kron(\n",
        "            torch.eye(self.Nt, dtype=self.dtype, device=self.device),\n",
        "            self.rt * self.In\n",
        "        )\n",
        "        self.Jnt = torch.kron(\n",
        "            torch.eye(self.Nt, dtype=self.dtype, device=self.device),\n",
        "            self.J\n",
        "        )\n",
        "\n",
        "        # Line impedance: Zt = Rt + ω0(J * Lt)\n",
        "        self.Zt = self.Rt + self.omega0 * (self.Jnt @ self.Lt)\n",
        "\n",
        "        self.update_network_matrices()\n",
        "\n",
        "    def update_breaker_status(self, status: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Update breaker status (True = closed/connected, False = open).\n",
        "        \"\"\"\n",
        "        self.breaker_status = status.to(device=self.device)\n",
        "        self.update_network_matrices()\n",
        "\n",
        "    def update_network_matrices(self):\n",
        "        \"\"\"\n",
        "        Update the active network incidence matrix and any dependent terms\n",
        "        based on breaker status. In the original code, the final lines also\n",
        "        update the load admittance matrix, but that was left incomplete.\n",
        "        \"\"\"\n",
        "        self.B_active = self.B.clone()\n",
        "\n",
        "        # If you have more Y-matrix computations, place them here as well.\n",
        "\n",
        "    def calculate_total_currents(self, v_nodes: torch.Tensor, i_line: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calculate total current injections io, including line or load effects\n",
        "        if needed. In your partial code, it simply returns B_active @ i_line.\n",
        "        \"\"\"\n",
        "        i_conv = self.B_active @ i_line\n",
        "        return i_conv\n",
        "\n",
        "\n",
        "    def compute_algebraic_line_currents(self, v: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Given the converter node voltages v (of shape [2*Nc]), compute the steady-state\n",
        "        line currents and the common node voltage v_common.\n",
        "        For each converter i:\n",
        "            i_line,i = Z_i^{-1}(v_i - v_common)\n",
        "        with the common node voltage given by:\n",
        "            v_common = rL * sum_{i=1}^{Nc} i_line,i\n",
        "        which rearranges to:\n",
        "            (I + rL * sum_i Z_i^{-1}) * v_common = rL * sum_i (Z_i^{-1} v_i)\n",
        "        \"\"\"\n",
        "        Nc = self.Nc\n",
        "        device = self.device\n",
        "        dtype = self.dtype\n",
        "\n",
        "        # Reshape v so that each row corresponds to a 2D converter voltage.\n",
        "        v_nodes = v.view(Nc, 2)\n",
        "\n",
        "        # Accumulate sums for the inversion.\n",
        "        S = torch.zeros((2, 2), dtype=dtype, device=device)\n",
        "        T = torch.zeros((2,),   dtype=dtype, device=device)\n",
        "        Z_inv_list = []  # store each 2x2 block inverse for later use\n",
        "\n",
        "        for i in range(Nc):\n",
        "            idx = slice(2 * i, 2 * (i + 1))\n",
        "            Z_i = self.Zt[idx, idx]\n",
        "            Z_i_inv = torch.linalg.inv(Z_i)\n",
        "            Z_inv_list.append(Z_i_inv)\n",
        "            S = S + Z_i_inv\n",
        "            T = T + (Z_i_inv @ v_nodes[i])\n",
        "\n",
        "        I2 = torch.eye(2, dtype=dtype, device=device)\n",
        "        # Solve for v_common: (I + rL * S) * v_common = rL * T\n",
        "        v_common = torch.linalg.solve(I2 + self.rL * S, self.rL * T)\n",
        "\n",
        "        # Now compute each line current: i_line,i = Z_i^{-1}(v_i - v_common)\n",
        "        i_line_blocks = []\n",
        "        for i, Z_i_inv in enumerate(Z_inv_list):\n",
        "            i_line_i = Z_i_inv @ (v_nodes[i] - v_common)\n",
        "            i_line_blocks.append(i_line_i)\n",
        "        i_line = torch.cat(i_line_blocks, dim=0)\n",
        "\n",
        "        return i_line, v_common\n",
        "\n",
        "    def line_dynamics(self, v: torch.Tensor, i_line: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Equation for line dynamics:\n",
        "        L_t (d/dt i_line) = - Z_t i_line + B^T (voltage differences).\n",
        "        In your partial code, there's also mention of load at the common node.\n",
        "        Here, we replicate the structure provided.\n",
        "        \"\"\"\n",
        "        # Current sum at the common node\n",
        "        # i_sum = -sum of all converter node currents\n",
        "        i_sum = torch.sum((self.B_active @ i_line).view(self.Nc, 2), dim=0)\n",
        "        # Common node voltage = rL * i_sum\n",
        "        v_common = self.rL * i_sum\n",
        "\n",
        "        # Voltage difference\n",
        "        # Expand v_common for each line so that each gets subtracted\n",
        "        # (In the snippet, you used a tile approach. Here we replicate manually.)\n",
        "        # B_active.T @ v yields shape [2*Nt], but we also subtract the same v_common for each line\n",
        "        v_diff = (self.B_active.T @ v) - torch.cat([v_common for _ in range(self.Nt)], dim=0)\n",
        "\n",
        "        # Right-hand side\n",
        "        rhs = -self.Zt @ i_line + self.B_active.T @ v_diff\n",
        "        # For numerical stability, you can add a tiny regularization to Lt\n",
        "        Lt_reg = self.Lt\n",
        "        di_line = torch.linalg.solve(Lt_reg, rhs)\n",
        "        return di_line\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# ConverterControl in PyTorch\n",
        "##############################################################################\n",
        "class ConverterControl:\n",
        "    \"\"\"\n",
        "    Implementation of converter dynamics and control from eqns. 18, 20, 22, 23.\n",
        "    \"\"\"\n",
        "    def __init__(self, network: PowerSystemNetwork, params: dict):\n",
        "\n",
        "        self.network = network\n",
        "        self.device = network.device\n",
        "        self.dtype = network.dtype\n",
        "\n",
        "        # Filter parameters (Table I)\n",
        "        self.rf = 0.124\n",
        "        self.lf = 1e-3\n",
        "        self.cf = 24e-6\n",
        "\n",
        "        # Per-converter filter conductances\n",
        "        gf_np = [1/0.124, 1/0.124, 1/0.124]\n",
        "        self.gf = torch.tensor(gf_np, dtype=self.dtype, device=self.device)\n",
        "\n",
        "        # Control gains\n",
        "        self.eta = params['eta']\n",
        "        self.eta_a = params['eta_a']\n",
        "        self.Kp_v = params['Kp_v']\n",
        "        self.Ki_v = params['Ki_v']\n",
        "        self.Kp_f = params['Kp_f']\n",
        "        self.Ki_f = params['Ki_f']\n",
        "\n",
        "\n",
        "        # Converter operating states\n",
        "        self.converter_states = {\n",
        "            i: {\n",
        "                'active': False,           # converter energized\n",
        "                'voltage_control': False,  # voltage control loop active\n",
        "                'power_control': False     # power control loop active\n",
        "            }\n",
        "            for i in range(self.network.Nc)\n",
        "        }\n",
        "\n",
        "        # We store setpoints at the \"converter\" level so we can easily update them\n",
        "        self.setpoints = Setpoints(\n",
        "            v_star=torch.zeros(self.network.Nc, dtype=self.dtype, device=self.device),\n",
        "            p_star=torch.zeros(self.network.Nc, dtype=self.dtype, device=self.device),\n",
        "            q_star=torch.zeros(self.network.Nc, dtype=self.dtype, device=self.device),\n",
        "            theta_star=torch.zeros(self.network.Nc, dtype=self.dtype, device=self.device)\n",
        "        )\n",
        "\n",
        "        # Prepare filter and control matrices\n",
        "        self.setup_converter_matrices()\n",
        "    def rebuild_control_matrices(self):\n",
        "        \"\"\"Reassemble the control matrices using current learnable parameters.\"\"\"\n",
        "        Nc = self.network.Nc\n",
        "        In = self.network.In\n",
        "\n",
        "        self.Kp_v_mat = torch.kron(\n",
        "            torch.eye(Nc, dtype=self.dtype, device=self.device),\n",
        "            self.Kp_v * In\n",
        "        )\n",
        "        self.Ki_v_mat = torch.kron(\n",
        "            torch.eye(Nc, dtype=self.dtype, device=self.device),\n",
        "            self.Ki_v * In\n",
        "        )\n",
        "        self.Kp_f_mat = torch.kron(\n",
        "            torch.eye(Nc, dtype=self.dtype, device=self.device),\n",
        "            self.Kp_f * In\n",
        "        )\n",
        "        self.Ki_f_mat = torch.kron(\n",
        "            torch.eye(Nc, dtype=self.dtype, device=self.device),\n",
        "            self.Ki_f * In\n",
        "        )\n",
        "    def setup_converter_matrices(self):\n",
        "        Nc = self.network.Nc\n",
        "        In = self.network.In\n",
        "        J = self.network.J\n",
        "        omega0 = self.network.omega0\n",
        "\n",
        "        # Large block diagonal versions\n",
        "        self.Lf = torch.kron(torch.eye(Nc, dtype=self.dtype, device=self.device), self.lf * In)\n",
        "        self.Rf = torch.kron(torch.eye(Nc, dtype=self.dtype, device=self.device), self.rf * In)\n",
        "        self.Cf = torch.kron(torch.eye(Nc, dtype=self.dtype, device=self.device), self.cf * In)\n",
        "        self.Gf = torch.kron(\n",
        "            torch.diag(self.gf.to(self.dtype)), In\n",
        "        ).to(device=self.device, dtype=self.dtype)\n",
        "        self.Jnc = torch.kron(torch.eye(Nc, dtype=self.dtype, device=self.device), J)\n",
        "\n",
        "        # Filter impedance/admittance\n",
        "        self.Zf = self.Rf + omega0 * (self.Jnc @ self.Lf)\n",
        "        self.Yf = -omega0 * (self.Jnc @ self.Cf)\n",
        "\n",
        "        # PI control gains\n",
        "        Kp_v_mat = self.Kp_v\n",
        "        Ki_v_mat = self.Ki_v\n",
        "        Kp_f_mat = self.Kp_f\n",
        "        Ki_f_mat = self.Ki_f\n",
        "\n",
        "        # For dimension [2*Nc, 2*Nc], scale identity blocks\n",
        "        self.Kp_v_mat = torch.kron(\n",
        "            torch.eye(Nc, dtype=self.dtype, device=self.device),\n",
        "            Kp_v_mat * In\n",
        "        )\n",
        "        self.Ki_v_mat = torch.kron(\n",
        "            torch.eye(Nc, dtype=self.dtype, device=self.device),\n",
        "            Ki_v_mat * In\n",
        "        )\n",
        "        self.Kp_f_mat = torch.kron(\n",
        "            torch.eye(Nc, dtype=self.dtype, device=self.device),\n",
        "            Kp_f_mat * In\n",
        "        )\n",
        "        self.Ki_f_mat = torch.kron(\n",
        "            torch.eye(Nc, dtype=self.dtype, device=self.device),\n",
        "            Ki_f_mat * In\n",
        "        )\n",
        "\n",
        "    def update_converter_state(self, idx, active, voltage_control, power_control):\n",
        "        self.converter_states[idx].update({\n",
        "            'active': active,\n",
        "            'voltage_control': voltage_control,\n",
        "            'power_control': power_control\n",
        "        })\n",
        "\n",
        "    def calculate_K(self, idx, setpoints):\n",
        "        \"\"\"\n",
        "        Power-sharing matrix K = (1/v_star^2) * R(kappa) * [p_star  -q_star; q_star  p_star].\n",
        "        \"\"\"\n",
        "        v_star = setpoints.v_star[idx]\n",
        "        p_star = setpoints.p_star[idx]\n",
        "        q_star = setpoints.q_star[idx]\n",
        "\n",
        "        # system-level kappa\n",
        "        kappa = torch.atan(torch.tensor(self.network.omega0) * torch.tensor(self.network.lt) / torch.tensor(self.network.rt))\n",
        "        R_kappa = torch.tensor([\n",
        "            [torch.cos(kappa), -torch.sin(kappa)],\n",
        "            [torch.sin(kappa),  torch.cos(kappa)]\n",
        "        ], dtype=self.dtype, device=self.device)\n",
        "\n",
        "        P = torch.tensor([\n",
        "            [p_star, q_star],\n",
        "            [-q_star,  p_star]\n",
        "        ], dtype=self.dtype, device=self.device)\n",
        "\n",
        "        K_mat = (1.0 / (v_star**2)) * (R_kappa @ P)\n",
        "        return K_mat\n",
        "\n",
        "    def calculate_Phi(self, v_hat_local, idx, setpoints):\n",
        "        \"\"\"\n",
        "        Φ = 1 - ||v_hat||^2 / v_star^2\n",
        "        \"\"\"\n",
        "        v_star = setpoints.v_star[idx]\n",
        "        norm_vhat = torch.norm(v_hat_local)\n",
        "        return 1.0 - (norm_vhat**2) / (v_star**2)\n",
        "\n",
        "    ########################################################################\n",
        "    # Filter dynamics\n",
        "    ########################################################################\n",
        "    def filter_dynamics_active(self, idx, v_local, i_f_local, vm_local,\n",
        "                               v_full, i_line):\n",
        "        \"\"\"\n",
        "        Cf dv/dt = -Yf v - i_o + i_f\n",
        "        Lf di_f/dt = -Zf i_f - v_local + vm_local\n",
        "        \"\"\"\n",
        "        # index slice\n",
        "        idx_slice = slice(2*idx, 2*(idx+1))\n",
        "\n",
        "        Yf_local = self.Yf[idx_slice, idx_slice]\n",
        "        Zf_local = self.Zf[idx_slice, idx_slice]\n",
        "\n",
        "        i_total = self.network.calculate_total_currents(v_full, i_line)\n",
        "        i_o_local = i_total[idx_slice]\n",
        "\n",
        "        dv = (1.0 / self.cf) * (-Yf_local @ v_local - i_o_local + i_f_local)\n",
        "        dif = (1.0 / self.lf) * (-Zf_local @ i_f_local - v_local + vm_local)\n",
        "        return dv, dif\n",
        "\n",
        "    def filter_dynamics_inactive(self, idx, v_local, i_f_local, v_full, i_line):\n",
        "        \"\"\"\n",
        "        When the converter is inactive but still connected (breaker closed),\n",
        "        replicate the RLC filter + any network current.\n",
        "        \"\"\"\n",
        "        idx_slice = slice(2*idx, 2*(idx+1))\n",
        "\n",
        "        Yf_local = self.Yf[idx_slice, idx_slice]\n",
        "        Zf_local = self.Zf[idx_slice, idx_slice]\n",
        "\n",
        "        i_total = self.network.calculate_total_currents(v_full, i_line)\n",
        "        i_o_local = i_total[idx_slice]\n",
        "\n",
        "        # Typically you might do something with the DC bus, but we set it to 0 here\n",
        "        dv = (1.0 / self.cf) * (-Yf_local @ v_local - i_o_local + i_f_local)\n",
        "        # The code snippet sets the derivative of i_f to zero. We replicate that:\n",
        "        dif = (1.0 / self.lf) * (-Zf_local @ i_f_local - v_local )*0\n",
        "        return dv, dif\n",
        "\n",
        "    ########################################################################\n",
        "    # Voltage control: eqns. (20), (22a)\n",
        "    ########################################################################\n",
        "    def voltage_control(self, idx, v_node, vhat_node, i_line,\n",
        "                        zeta_v_node, v_full, setpoints):\n",
        "        \"\"\"\n",
        "        If power_control is active, do the full dVOC eqn, otherwise do a simpler\n",
        "        voltage P-control. Also compute integrator.\n",
        "        \"\"\"\n",
        "        if not (self.converter_states[idx]['voltage_control'] and\n",
        "                self.converter_states[idx]['active']):\n",
        "            # no control action\n",
        "            return torch.zeros(2, dtype=self.dtype, device=self.device), \\\n",
        "                   torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "\n",
        "        idx_slice = slice(2*idx, 2*(idx+1))\n",
        "        i_total = self.network.calculate_total_currents(v_full, i_line)\n",
        "        i_inj = i_total[idx_slice]\n",
        "\n",
        "        if self.converter_states[idx]['power_control']:\n",
        "            # Full dVOC\n",
        "            K = self.calculate_K(idx, setpoints)\n",
        "            phi_val = self.calculate_Phi(vhat_node, idx, setpoints)\n",
        "\n",
        "            # Rotation R(kappa) for i_inj\n",
        "            kappa = torch.atan(torch.tensor(self.network.omega0 * self.network.lt / self.network.rt))\n",
        "            R_kappa = torch.tensor([\n",
        "                [torch.cos(kappa), -torch.sin(kappa)],\n",
        "                [torch.sin(kappa),  torch.cos(kappa)]\n",
        "            ], dtype=self.dtype, device=self.device)\n",
        "\n",
        "            dvhat = self.eta * (K @ vhat_node\n",
        "                                - R_kappa @ i_inj\n",
        "                                + self.eta_a * phi_val * vhat_node)\n",
        "        else:\n",
        "            # Basic voltage regulation\n",
        "            v_star = setpoints.v_star[idx]\n",
        "            # We do a scalar difference for magnitude\n",
        "            v_mag = torch.norm(v_node) + 1e-12\n",
        "            dvhat = -self.Kp_v * ((v_mag - v_star) * (v_node / v_mag))\n",
        "\n",
        "        # Voltage integrator\n",
        "        dzeta_v = v_node - vhat_node\n",
        "        return dvhat, dzeta_v\n",
        "\n",
        "    def calculate_reference_current(self, idx, v_node, vhat_node,\n",
        "                                    i_line, zeta_v_node, v_full):\n",
        "        \"\"\"\n",
        "        i_ref = Yf v + i_inj - Kp_v(...) - Ki_v(...)\n",
        "        or a simpler version if power_control is off.\n",
        "        \"\"\"\n",
        "        idx_slice = slice(2*idx, 2*(idx+1))\n",
        "\n",
        "        if not self.converter_states[idx]['active']:\n",
        "            return torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "\n",
        "        Yf_local = self.Yf[idx_slice, idx_slice]\n",
        "\n",
        "        if self.converter_states[idx]['voltage_control']:\n",
        "            i_total = self.network.calculate_total_currents(v_full, i_line)\n",
        "            i_inj = i_total[idx_slice]\n",
        "\n",
        "            if self.converter_states[idx]['power_control']:\n",
        "                # Full feed-forward\n",
        "                i_ref = (Yf_local @ v_node\n",
        "                         + i_inj\n",
        "                         - self.Kp_v_mat[idx_slice, idx_slice] @ (v_node - vhat_node)\n",
        "                         - self.Ki_v_mat[idx_slice, idx_slice] @ zeta_v_node)\n",
        "            else:\n",
        "                # Voltage control, no power sharing\n",
        "                i_ref = (Yf_local @ v_node\n",
        "                         - self.Kp_v_mat[idx_slice, idx_slice] @ (v_node - vhat_node)\n",
        "                         - self.Ki_v_mat[idx_slice, idx_slice] @ zeta_v_node)\n",
        "        else:\n",
        "            # Current control only\n",
        "            i_ref = Yf_local @ v_node\n",
        "\n",
        "        return i_ref\n",
        "\n",
        "    ########################################################################\n",
        "    # Current control: eqn. (23)\n",
        "    ########################################################################\n",
        "    def current_control(self, idx, v_node, i_f_node, i_ref_node, zeta_f_node):\n",
        "        \"\"\"\n",
        "        vm = Zf i_f + v - Kp_f(if - if^r) - Ki_f zeta_f\n",
        "        d/dt zeta_f = if - if^r\n",
        "        \"\"\"\n",
        "        if not self.converter_states[idx]['active']:\n",
        "            return torch.zeros(2, dtype=self.dtype, device=self.device), \\\n",
        "                   torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "\n",
        "        idx_slice = slice(2*idx, 2*(idx+1))\n",
        "        Zf_local = self.Zf[idx_slice, idx_slice]\n",
        "\n",
        "        vm_local = (Zf_local @ i_f_node\n",
        "                    + v_node\n",
        "                    - self.Kp_f_mat[idx_slice, idx_slice] @ (i_f_node - i_ref_node)\n",
        "                    - self.Ki_f_mat[idx_slice, idx_slice] @ zeta_f_node)\n",
        "\n",
        "        dzeta_f = i_f_node - i_ref_node\n",
        "        return vm_local, dzeta_f\n",
        "\n",
        "    ########################################################################\n",
        "    # Full converter dynamics for one converter\n",
        "    ########################################################################\n",
        "\n",
        "    def compute_converter_dynamics(self, idx, full_state, setpoints, i_line):\n",
        "        Nc = self.network.Nc\n",
        "        n_conv = 2 * Nc\n",
        "\n",
        "        # New state slicing:\n",
        "        # full_state = [vhat, v, zeta_v, i_f, zeta_f]\n",
        "        vhat   = full_state[0:n_conv]\n",
        "        v      = full_state[n_conv : 2*n_conv]\n",
        "        zeta_v = full_state[2*n_conv : 3*n_conv]\n",
        "        i_f    = full_state[3*n_conv : 4*n_conv]\n",
        "        zeta_f = full_state[4*n_conv : 5*n_conv]\n",
        "\n",
        "        idx_slice = slice(2*idx, 2*(idx+1))\n",
        "\n",
        "        vhat_local   = vhat[idx_slice]\n",
        "        v_local      = v[idx_slice]\n",
        "        zeta_v_local = zeta_v[idx_slice]\n",
        "        i_f_local    = i_f[idx_slice]\n",
        "        zeta_f_local = zeta_f[idx_slice]\n",
        "        v_full       = v  # use the entire node voltage vector\n",
        "        # Default zero derivatives\n",
        "        dvhat = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "        dv_ = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "        dzeta_v_ = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "        dif_ = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "        dzeta_f_ = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "\n",
        "        # Check breaker\n",
        "        if self.network.breaker_status[idx]:\n",
        "            if self.converter_states[idx]['active']:\n",
        "                # Active\n",
        "                dvhat, dzeta_v_ = self.voltage_control(\n",
        "                    idx, v_local, vhat_local, i_line, zeta_v_local, v_full, setpoints\n",
        "                )\n",
        "                i_ref_local = self.calculate_reference_current(\n",
        "                    idx, v_local, vhat_local, i_line, zeta_v_local, v_full\n",
        "                )\n",
        "                vm_local, dzeta_f_ = self.current_control(\n",
        "                    idx, v_local, i_f_local, i_ref_local, zeta_f_local\n",
        "                )\n",
        "                dv_, dif_ = self.filter_dynamics_active(\n",
        "                    idx, v_local, i_f_local, vm_local, v_full, i_line\n",
        "                )\n",
        "            else:\n",
        "                # Inactive but connected\n",
        "                dv_, dif_ = self.filter_dynamics_inactive(\n",
        "                    idx, v_local, i_f_local, v_full, i_line\n",
        "                )\n",
        "        else:\n",
        "            # breaker is open -> no conduction\n",
        "            # purely resistor/inductor discharge if that is relevant\n",
        "            dif_ = -(self.rf/self.lf) * i_f_local\n",
        "\n",
        "        return dvhat, dv_, dzeta_v_, dif_, dzeta_f_\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# ConverterState: Scenario manager\n",
        "##############################################################################\n",
        "class ConverterState:\n",
        "    \"\"\"\n",
        "    Manage converter states and setpoints for simulation sequence.\n",
        "    \"\"\"\n",
        "    def __init__(self, converter_control: ConverterControl):\n",
        "        self.converter = converter_control\n",
        "        self.network = converter_control.network\n",
        "        device = self.network.device\n",
        "        dtype = self.network.dtype\n",
        "\n",
        "        # Initial setpoints\n",
        "        self.initial_setpoints = {\n",
        "            'v_star': torch.tensor([120.0, 120.0, 120.0], dtype=dtype, device=device),\n",
        "            'p_star': torch.tensor([43.2, 41.0, 41.0], dtype=dtype, device=device),\n",
        "            'q_star': torch.tensor([-.9, 0.5, -0.5], dtype=dtype, device=device)\n",
        "        }\n",
        "\n",
        "        # Final setpoints\n",
        "        self.final_setpoints = {\n",
        "            'v_star': torch.tensor([120.0, 120.0, 120.0], dtype=dtype, device=device),\n",
        "            'p_star': torch.tensor([43.2, 41.0, 41.0], dtype=dtype, device=device),\n",
        "            'q_star': torch.tensor([-.9, 0.5, -0.5], dtype=dtype, device=device)\n",
        "        }\n",
        "\n",
        "        # Connection times\n",
        "        self.t_connect = {\n",
        "            0: 0.0,  # conv1\n",
        "            1: 0.0,  # conv2\n",
        "            2: 0   # conv3 at t=1.5\n",
        "        }\n",
        "\n",
        "        # Control activation times\n",
        "        self.t_sequence = {\n",
        "            0: {'current': 0.0, 'voltage': 0.0, 'power': 0.0},\n",
        "            1: {'current': 0.0, 'voltage': 0.0, 'power': 0.0},\n",
        "            2: {'current': 0, 'voltage': 0, 'power': 0}\n",
        "        }\n",
        "\n",
        "        # Setpoint change time\n",
        "        self.t_setpoint_change = 3.5\n",
        "\n",
        "    def update_states(self, t: float):\n",
        "        \"\"\"\n",
        "        At time t, update:\n",
        "         - breaker_status\n",
        "         - converter states\n",
        "         - setpoints\n",
        "        \"\"\"\n",
        "        breaker_status_list = []\n",
        "        for i in range(self.network.Nc):\n",
        "            # Here we keep them always closed.\n",
        "            # If you have a scenario where they physically open, adjust accordingly.\n",
        "            breaker_status_list.append(True)\n",
        "        self.network.update_breaker_status(torch.tensor(breaker_status_list, dtype=torch.bool, device=self.network.device))\n",
        "\n",
        "        # Update each converter state\n",
        "        for i in range(self.network.Nc):\n",
        "            if t >= self.t_connect[i]:\n",
        "                is_active = (t >= self.t_sequence[i]['current'])\n",
        "                v_ctl = (t >= self.t_sequence[i]['voltage'])\n",
        "                p_ctl = (t >= self.t_sequence[i]['power'])\n",
        "                self.converter.update_converter_state(i, is_active, v_ctl, p_ctl)\n",
        "            else:\n",
        "                self.converter.update_converter_state(i, False, False, False)\n",
        "\n",
        "        # Update global setpoints\n",
        "        if t >= self.t_setpoint_change:\n",
        "            sps = self.final_setpoints\n",
        "        else:\n",
        "            sps = self.initial_setpoints\n",
        "\n",
        "        self.converter.setpoints = Setpoints(\n",
        "            v_star=sps['v_star'],\n",
        "            p_star=sps['p_star'],\n",
        "            q_star=sps['q_star'],\n",
        "            theta_star=torch.zeros(self.network.Nc, dtype=self.network.dtype, device=self.network.device)\n",
        "        )\n",
        "class MultiConverterSimulation(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Complete grey‑box simulation with automatic switching between\n",
        "\n",
        "        • algebraic line‑currents  (black‑start)      – 6·Nc states\n",
        "        • differential line‑currents (load‑change)    – 8·Nc+2·Nt states\n",
        "\n",
        "    Everything else (controller, constraints, optimisation) is unchanged.\n",
        "    \"\"\"\n",
        "    # ------------------------------------------------------------------ INIT\n",
        "    def __init__(self, device='cuda', dtype=torch.float64):\n",
        "        super().__init__()\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 0.  high‑level flags\n",
        "        self.device = device\n",
        "        self.dtype  = dtype\n",
        "        #    “True”  → integrate d i_line /dt              (17)\n",
        "        #    “False” → i_line obtained algebraically via   (18)\n",
        "        self.integrate_line_dynamics: bool = False\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 1.  learnable control parameters  (same initial values)\n",
        "        self.eta    = torch.nn.Parameter(torch.tensor(9.66  , dtype=dtype, device=device))\n",
        "        self.eta_a  = torch.nn.Parameter(torch.tensor(4.6256, dtype=dtype, device=device))\n",
        "        self.Kp_v   = torch.nn.Parameter(torch.tensor(0.6917, dtype=dtype, device=device))\n",
        "        self.Ki_v   = torch.nn.Parameter(torch.tensor(0.8552, dtype=dtype, device=device))\n",
        "        self.Kp_f   = torch.nn.Parameter(torch.tensor(7.22  , dtype=dtype, device=device))\n",
        "        self.Ki_f   = torch.nn.Parameter(torch.tensor(14.04 , dtype=dtype, device=device))\n",
        "\n",
        "        # Lagrange multipliers (unchanged)\n",
        "        self.lambda_cond4 = torch.nn.Parameter(torch.tensor(1.0, dtype=dtype, device=device))\n",
        "        self.lambda_cond5 = torch.nn.Parameter(torch.tensor(1.0, dtype=dtype, device=device))\n",
        "        self.lambda_cond6 = torch.nn.Parameter(torch.tensor(1.0, dtype=dtype, device=device))\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 2.  physical system\n",
        "        self.network    = PowerSystemNetwork(device=device, dtype=dtype)\n",
        "        self.converter  = ConverterControl(\n",
        "            self.network,\n",
        "            {'eta': self.eta, 'eta_a': self.eta_a,\n",
        "             'Kp_v': self.Kp_v, 'Ki_v': self.Ki_v,\n",
        "             'Kp_f': self.Kp_f, 'Ki_f': self.Ki_f})\n",
        "\n",
        "        self.state_handler = ConverterState(self.converter)\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 3.  simulation parameters\n",
        "        self.dt     = 0.5e-3\n",
        "        self.T_sim  = .4\n",
        "\n",
        "        # pre‑allocated containers\n",
        "        self.default_equilibrium_target     = None\n",
        "        self.scenario_equilibrium_targets   = {}\n",
        "\n",
        "        # bookkeeping for disturbance scenario (unchanged)\n",
        "        self.network.rL = torch.tensor(self.network.rL,dtype=self.dtype, device=self.device)\n",
        "        self.scenario              = \"black_start\"\n",
        "        self.original_rL           = torch.tensor(self.network.rL.clone().detach(),dtype=self.dtype, device=self.device)\n",
        "        self.disturbance           = None\n",
        "        self.disturbance_applied   = False\n",
        "        self.disturbance_time      = 0.05\n",
        "\n",
        "        # small cache for constraints\n",
        "        self._constraint_cache = {}\n",
        "\n",
        "\n",
        "    def check_equilibrium_residual(self, equilibrium_guess: Union[torch.Tensor, np.ndarray], t_steady_val: float = 10.0) -> float:\n",
        "        \"\"\"\n",
        "        Computes the L2 norm of the system dynamics (dx/dt) for a given state guess,\n",
        "        representing the residual error from a true equilibrium point.\n",
        "\n",
        "        Args:\n",
        "            equilibrium_guess (Union[torch.Tensor, np.ndarray]): The state vector guess\n",
        "                                                                for the equilibrium point.\n",
        "            t_steady_val (float): A time value representing steady state conditions\n",
        "                                  (e.g., after setpoint changes). Defaults to 10.0.\n",
        "\n",
        "        Returns:\n",
        "            float: The L2 norm of the state derivative vector (residual). Returns\n",
        "                  float('inf') if the calculation fails.\n",
        "        \"\"\"\n",
        "        # Ensure the guess is a PyTorch tensor with correct dtype and device\n",
        "        if isinstance(equilibrium_guess, np.ndarray):\n",
        "            guess_tensor = torch.tensor(equilibrium_guess, dtype=self.dtype, device=self.device)\n",
        "        elif isinstance(equilibrium_guess, torch.Tensor):\n",
        "            guess_tensor = equilibrium_guess.to(dtype=self.dtype, device=self.device)\n",
        "        else:\n",
        "            print(\"Error: equilibrium_guess must be a PyTorch Tensor or NumPy array.\")\n",
        "            return float('inf')\n",
        "\n",
        "        # Ensure state vector has the correct size (adjust if state dimension changes)\n",
        "        expected_size = 5 * 2 * self.network.Nc # Based on [vhat, v, zeta_v, i_f, zeta_f]\n",
        "        if guess_tensor.shape[0] != expected_size:\n",
        "            print(f\"Error: equilibrium_guess has wrong shape {guess_tensor.shape}. Expected ({expected_size},).\")\n",
        "            return float('inf')\n",
        "\n",
        "\n",
        "        # Prepare steady-state time tensor\n",
        "        t_steady = torch.tensor(t_steady_val, dtype=self.dtype, device=self.device)\n",
        "\n",
        "        print(f\"Checking residual for guess (first 6 elements): {guess_tensor[:6].cpu().numpy()}...\")\n",
        "        print(f\"Using t_steady = {t_steady_val}\")\n",
        "\n",
        "        residual_norm = float('inf') # Default to infinity in case of error\n",
        "        try:\n",
        "            # Calculate the derivative dx/dt at the guess state and steady time\n",
        "            # Use no_grad as we only need the value, not gradients\n",
        "            with torch.no_grad():\n",
        "                # system_equations uses the current self.network.rL and the setpoints\n",
        "                # determined by state_handler(t_steady)\n",
        "                dstate = self.system_equations_algebraic(t_steady, guess_tensor)\n",
        "\n",
        "            # Check if the derivative calculation resulted in NaN/Inf\n",
        "            if torch.isnan(dstate).any() or torch.isinf(dstate).any():\n",
        "                print(\"Warning: system_equations returned NaN or Inf during residual check.\")\n",
        "            else:\n",
        "                # Calculate the L2 norm (Euclidean norm) of the derivative vector\n",
        "                residual_norm = torch.norm(dstate).item()\n",
        "                print(f\"Computed residual norm: {residual_norm:.6e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during residual calculation: {e}\")\n",
        "            # Keep residual_norm as infinity\n",
        "\n",
        "        return residual_norm\n",
        "    def initialize_state(self, scenario: str):\n",
        "        \"\"\"\n",
        "        Create a *consistent* initial state for whichever network model\n",
        "        is active (with OR without i_line).\n",
        "        \"\"\"\n",
        "        if scenario == \"black_start\":\n",
        "            return self.initialize_black_start()          # 5·Nc×2 elements\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # load‑change → need i_line states as well\n",
        "        x0_alg = self.initialize_from_equilibrium()       # algebraic layout\n",
        "        return x0_alg\n",
        "\n",
        "    def initialize_from_equilibrium(self):\n",
        "        \"\"\"Initialize state from equilibrium target with small perturbation\"\"\"\n",
        "        Nc = self.network.Nc\n",
        "        n_conv = 2 * Nc\n",
        "        state_size = 5 * n_conv  # [vhat, v, zeta_v, i_f, zeta_f]\n",
        "\n",
        "        # Equilibrium state (from original code)\n",
        "        equilibrium_target = torch.tensor([ 1.19999892e+02,  2.98296769e-02,  1.19999872e+02,  2.78635891e-02,\n",
        "        1.19999530e+02,  2.82802388e-02,  3.59346305e-01,  5.99563038e-03,\n",
        "        3.41118357e-01, -5.83582256e-03,  3.42865166e-01, -1.38492159e-04,\n",
        "        1.20000446e+02,  2.98451641e-02,  1.20000426e+02,  2.78792361e-02,\n",
        "        1.20000084e+02,  2.82958090e-02, -4.44584345e-04, -2.32653329e-05,\n",
        "       -4.44971217e-04, -2.35086964e-05, -4.44918487e-04, -2.34119242e-05,\n",
        "        3.59616321e-01, -1.07974249e+00,  3.41370586e-01, -1.09157377e+00,\n",
        "        3.43121164e-01, -1.08587334e+00, -1.49898137e-06,  4.54956374e-06,\n",
        "       -1.42244797e-06,  4.59992635e-06, -1.43564634e-06,  4.58469070e-06], dtype=self.dtype, device=self.device)\n",
        "\n",
        "\n",
        "\n",
        "        # Ensure the state has the correct size\n",
        "        if equilibrium_target.shape[0] < state_size:\n",
        "            # Pad if needed\n",
        "            equilibrium_target = torch.cat([\n",
        "                equilibrium_target,\n",
        "                torch.zeros(state_size - equilibrium_target.shape[0],\n",
        "                           dtype=self.dtype, device=self.device)\n",
        "            ])\n",
        "\n",
        "        # Add small random perturbation (0.1% noise)\n",
        "        perturbation = torch.randn(state_size, dtype=self.dtype, device=self.device) * 0.001\n",
        "        x0 = equilibrium_target\n",
        "\n",
        "        return x0\n",
        "    def setup_scenario(self, scenario: str):\n",
        "        \"\"\"\n",
        "        Prepare network + controller for the requested operating condition\n",
        "        and decide whether we integrate the transmission‑line dynamics.\n",
        "        \"\"\"\n",
        "        self.scenario = scenario\n",
        "        print(f\"\\n--- Setting up scenario: {scenario} ---\")\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 0.  restore nominal load, clear previous disturbance\n",
        "        self.network.rL          = self.original_rL.clone().detach()\n",
        "        self.disturbance_applied = False\n",
        "        self.disturbance         = None\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 1.  decide integration mode  (key point of this re‑write!)\n",
        "        self.integrate_line_dynamics = (scenario == \"load_change\")\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 2.  common objects needed below\n",
        "        t_steady_for_eq  = 0.0  # we always want final set‑points\n",
        "        final_setpoints  = Setpoints(\n",
        "            v_star = self.state_handler.final_setpoints['v_star'],\n",
        "            p_star = self.state_handler.final_setpoints['p_star'],\n",
        "            q_star = self.state_handler.final_setpoints['q_star'],\n",
        "            theta_star = torch.zeros(self.network.Nc, dtype=self.dtype, device=self.device))\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 3.  make sure we have a *nominal* equilibrium reference\n",
        "        if self.default_equilibrium_target is None:\n",
        "            print(\"Calculating default equilibrium target …\")\n",
        "            guess = self.initialize_from_equilibrium()\n",
        "            self.default_equilibrium_target = self.compute_equilibrium_point(\n",
        "                t_steady_val = t_steady_for_eq, x0_guess = guess)\n",
        "            self.scenario_equilibrium_targets[\"default\"] = self.default_equilibrium_target\n",
        "\n",
        "        target_equilibrium_for_loss = self.default_equilibrium_target  # fallback\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 4.  scenario‑specific tweaks\n",
        "        if scenario == \"load_change\":\n",
        "            # (i)  change the load\n",
        "            self.network.rL = torch.tensor(115.0*.1, dtype=self.dtype, device=self.device)\n",
        "            print(f\"Scenario 'load_change': rL = {self.network.rL:.4f} Ω\")\n",
        "\n",
        "            # (ii) equilibrium for new load\n",
        "            prev_eq = self.scenario_equilibrium_targets.get('load_change')\n",
        "            eq      = self.compute_equilibrium_point(t_steady_val=0.0, x0_guess=prev_eq)\n",
        "            if eq is not None:\n",
        "                self.scenario_equilibrium_targets['load_change'] = eq\n",
        "                target_equilibrium_for_loss = eq\n",
        "                print(\"  … new equilibrium accepted (‖F‖<1e‑4).\")\n",
        "\n",
        "        elif scenario == \"black_start\":\n",
        "            print(\"Scenario 'black_start': using algebraic network (no line states).\")\n",
        "\n",
        "        # (other scenarios unchanged …)\n",
        "\n",
        "        self.scenario_equilibrium_targets[scenario] = target_equilibrium_for_loss\n",
        "        tgt = \"None\" if target_equilibrium_for_loss is None else str(target_equilibrium_for_loss[:6].cpu().numpy())+\"…\"\n",
        "        print(f\"Target equilibrium used by LOSS: {tgt}\")\n",
        "\n",
        "    # =============================================================  FORWARD\n",
        "    def forward(self, t: torch.Tensor, state: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Unified entry point used by `odeint`.\n",
        "        Delegates to the proper RHS depending on `self.integrate_line_dynamics`.\n",
        "        Disturbance injection kept identical to your previous logic.\n",
        "        \"\"\"\n",
        "        # ------ disturbance injection (unchanged) --------------------------\n",
        "        if (self.scenario == \"disturbance\"\n",
        "                and not self.disturbance_applied\n",
        "                and t >= self.disturbance_time):\n",
        "            Nc = self.network.Nc\n",
        "            n_conv = 2*Nc\n",
        "            i_f_off = 3*n_conv if not self.integrate_line_dynamics else 3*n_conv + 2*self.network.Nt\n",
        "            state       = state.clone()\n",
        "            state[i_f_off:i_f_off+2*Nc] += self.disturbance\n",
        "            self.disturbance_applied = True\n",
        "\n",
        "        # ---------------- choose the correct model ------------------------\n",
        "        if self.integrate_line_dynamics:\n",
        "            return self.system_equations_differential(t, state)\n",
        "        else:\n",
        "            return self.system_equations_algebraic(t, state)\n",
        "    def system_equations_algebraic(self, t, state):\n",
        "        \"\"\"\n",
        "        RHS using algebraic elimination of i_line (same as your old\n",
        "        `system_equations`).  State layout:\n",
        "            [vhat, v, zeta_v, i_f, zeta_f]\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            self.state_handler.update_states(float(t))\n",
        "\n",
        "        # update gain matrices\n",
        "        self.converter.eta   = self.eta\n",
        "        self.converter.eta_a = self.eta_a\n",
        "        self.converter.Kp_v  = self.Kp_v\n",
        "        self.converter.Ki_v  = self.Ki_v\n",
        "        self.converter.Kp_f  = self.Kp_f\n",
        "        self.converter.Ki_f  = self.Ki_f\n",
        "        self.converter.rebuild_control_matrices()\n",
        "\n",
        "        Nc        = self.network.Nc\n",
        "        n_conv    = 2*Nc\n",
        "\n",
        "        # -------------- unpack state --------------------------------------\n",
        "        vhat   = state[0:n_conv]\n",
        "        v      = state[n_conv:2*n_conv]\n",
        "        zeta_v = state[2*n_conv:3*n_conv]\n",
        "        i_f    = state[3*n_conv:4*n_conv]\n",
        "        zeta_f = state[4*n_conv:5*n_conv]\n",
        "\n",
        "        # -------------- compute algebraic network -------------------------\n",
        "        i_line, v_common = self.network.compute_algebraic_line_currents(v)\n",
        "\n",
        "        # -------------- converter dynamics --------------------------------\n",
        "        dvhat_list, dv_list, dzeta_v_list, dif_list, dzeta_f_list = [],[],[],[],[]\n",
        "        for idx in range(Nc):\n",
        "            dvh,dv,dzv,dif,dzf = self.converter.compute_converter_dynamics(\n",
        "                idx, torch.cat([vhat, v, zeta_v, i_f, zeta_f], 0),\n",
        "                self.converter.setpoints, i_line)\n",
        "            dvhat_list.append(dvh)\n",
        "            dv_list.append(dv)\n",
        "            dzeta_v_list.append(dzv)\n",
        "            dif_list.append(dif)\n",
        "            dzeta_f_list.append(dzf)\n",
        "\n",
        "        # -------------- stack & return ------------------------------------\n",
        "        return torch.cat([\n",
        "            torch.cat(dvhat_list),\n",
        "            torch.cat(dv_list),\n",
        "            torch.cat(dzeta_v_list),\n",
        "            torch.cat(dif_list),\n",
        "            torch.cat(dzeta_f_list)], 0)\n",
        "\n",
        "    # ------------------- differential line currents (load‑change) ---------\n",
        "    def system_equations_differential(self, t, state):\n",
        "        \"\"\"\n",
        "        RHS that *integrates* i_line (eqn 17).  Layout:\n",
        "            [vhat, i_line, v, zeta_v, i_f, zeta_f]\n",
        "        Basically identical to your previous `system_equationsx`.\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            self.state_handler.update_states(float(t))\n",
        "\n",
        "        self.converter.eta   = self.eta\n",
        "        self.converter.eta_a = self.eta_a\n",
        "        self.converter.Kp_v  = self.Kp_v\n",
        "        self.converter.Ki_v  = self.Ki_v\n",
        "        self.converter.Kp_f  = self.Kp_f\n",
        "        self.converter.Ki_f  = self.Ki_f\n",
        "        self.converter.rebuild_control_matrices()\n",
        "\n",
        "        Nc      = self.network.Nc\n",
        "        Nt      = self.network.Nt\n",
        "        n_conv  = 2*Nc\n",
        "        n_line  = 2*Nt\n",
        "\n",
        "        # -------------- unpack -------------------------------------------\n",
        "        vhat   = state[0:n_conv]\n",
        "        i_line = state[n_conv:n_conv+n_line]\n",
        "        v      = state[n_conv+n_line:2*n_conv+n_line]\n",
        "        zeta_v = state[2*n_conv+n_line:3*n_conv+n_line]\n",
        "        i_f    = state[3*n_conv+n_line:4*n_conv+n_line]\n",
        "        zeta_f = state[4*n_conv+n_line:5*n_conv+n_line]\n",
        "\n",
        "        # -------------- network differential eqn -------------------------\n",
        "        di_line = self.network.line_dynamics(v, i_line)\n",
        "\n",
        "        # -------------- converter dynamics -------------------------------\n",
        "        dvhat_list, dv_list, dzeta_v_list, dif_list, dzeta_f_list = [],[],[],[],[]\n",
        "        for idx in range(Nc):\n",
        "            dvh,dv,dzv,dif,dzf = self.converter.compute_converter_dynamics(\n",
        "                idx, torch.cat([vhat, v, zeta_v, i_f, zeta_f], 0),\n",
        "                self.converter.setpoints, i_line)\n",
        "            dvhat_list.append(dvh);   dv_list.append(dv)\n",
        "            dzeta_v_list.append(dzv); dif_list.append(dif)\n",
        "            dzeta_f_list.append(dzf)\n",
        "\n",
        "        # -------------- stack --------------------------------------------\n",
        "        return torch.cat([\n",
        "            torch.cat(dvhat_list),\n",
        "            di_line,\n",
        "            torch.cat(dv_list),\n",
        "            torch.cat(dzeta_v_list),\n",
        "            torch.cat(dif_list),\n",
        "            torch.cat(dzeta_f_list)], 0)\n",
        "\n",
        "\n",
        "    def run_simulation_for_scenario(self, scenario):\n",
        "        \"\"\"Run simulation for a specific scenario\"\"\"\n",
        "        # Setup scenario\n",
        "\n",
        "        self.setup_scenario(scenario)\n",
        "\n",
        "        # Prepare time steps\n",
        "        steps = int(self.T_sim / self.dt) + 1\n",
        "        t_span = torch.linspace(\n",
        "            0.0, self.T_sim, steps, dtype=self.dtype, device=self.device\n",
        "        )\n",
        "\n",
        "        # Initialize state based on scenario\n",
        "        x0 = self.initialize_state(scenario)\n",
        "\n",
        "        # Run simulation\n",
        "        sol = odeint(\n",
        "            func=self,\n",
        "            y0=x0,\n",
        "            t=t_span,\n",
        "\n",
        "            rtol=2*1e-5,\n",
        "            atol=2*1e-5,\n",
        "            method='radau'\n",
        "            )\n",
        "\n",
        "        return t_span, sol\n",
        "\n",
        "\n",
        "    def update_lagrange_multipliers(self, step_size=0.1):\n",
        "        \"\"\"\n",
        "        Update Lagrange multipliers using gradient ascent.\n",
        "\n",
        "        In the Lagrangian method, we maximize L with respect to λ.\n",
        "        λ_{k+1} = max(0, λ_k + step_size * g(x_k))\n",
        "        where g(x_k) are the constraint functions.\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            # Get current constraint values\n",
        "            stability_results = self.check_stability_conditions()\n",
        "\n",
        "            # Extract margins and convert to violation form g(x) <= 0\n",
        "            g4 = -stability_results[\"condition4\"][\"margin\"]\n",
        "            g5 = -stability_results[\"condition5\"][\"margin\"]\n",
        "            g6 = -stability_results[\"condition6\"][\"margin\"]\n",
        "\n",
        "            # Convert to tensors\n",
        "            g4_tensor = torch.tensor(g4, dtype=self.dtype, device=self.device)\n",
        "            g5_tensor = torch.tensor(g5, dtype=self.dtype, device=self.device)\n",
        "            g6_tensor = torch.tensor(g6, dtype=self.dtype, device=self.device)\n",
        "\n",
        "            # Update Lagrange multipliers (gradient ascent)\n",
        "            # We only increase multipliers when constraints are violated (g > 0)\n",
        "            self.lambda_cond4.data = torch.clamp(\n",
        "                self.lambda_cond4.data + step_size * torch.relu(g4_tensor),\n",
        "                min=0.0\n",
        "            )\n",
        "            self.lambda_cond5.data = torch.clamp(\n",
        "                self.lambda_cond5.data + step_size * torch.relu(g5_tensor),\n",
        "                min=0.0\n",
        "            )\n",
        "            self.lambda_cond6.data = torch.clamp(\n",
        "                self.lambda_cond6.data + step_size * torch.relu(g6_tensor),\n",
        "                min=0.0\n",
        "            )\n",
        "\n",
        "    def clear_constraint_cache(self):\n",
        "        \"\"\"Clear any cached constraint computations.\"\"\"\n",
        "        self._constraint_cache = {}\n",
        "\n",
        "    def initialize_constraint_cache(self):\n",
        "        \"\"\"Initialize cache for constraint computations.\"\"\"\n",
        "        self._constraint_cache = {\n",
        "            \"norm_BR\": None,\n",
        "            \"c2\": None,\n",
        "            \"c3\": None\n",
        "        }\n",
        "\n",
        "    def compute_lagrangian_loss(self, t_vec, sol, check_constraints_every=1):\n",
        "        \"\"\"\n",
        "        Compute loss using the Lagrangian method for constraints.\n",
        "        Original implementation, unchanged.\n",
        "        \"\"\"\n",
        "        # Original performance loss\n",
        "        performance_loss = self.compute_loss(t_vec, sol)\n",
        "\n",
        "        # Only check constraints every N steps or initialize counter\n",
        "        if not hasattr(self, '_opt_step_counter'):\n",
        "            self._opt_step_counter = 0\n",
        "            check_now = True\n",
        "        else:\n",
        "            check_now = (self._opt_step_counter % check_constraints_every == 0)\n",
        "            self._opt_step_counter += 1\n",
        "\n",
        "        # Check stability conditions or use cached results\n",
        "        if check_now:\n",
        "            # Clear any existing cache\n",
        "            self.clear_constraint_cache()\n",
        "\n",
        "            # Compute stability conditions\n",
        "            stability_results = self.check_stability_conditions()\n",
        "\n",
        "            # Store results for later use\n",
        "            self._last_stability_results = stability_results\n",
        "        else:\n",
        "            # Use previous results\n",
        "            stability_results = self._last_stability_results\n",
        "\n",
        "        # Get constraint values (negative margin means constraint violation)\n",
        "        margin4 = stability_results[\"condition4\"][\"margin\"]\n",
        "        margin5 = stability_results[\"condition5\"][\"margin\"]\n",
        "        margin6 = stability_results[\"condition6\"][\"margin\"]\n",
        "\n",
        "        # Convert to constraint functions g(x) <= 0 form\n",
        "        # Also convert to tensors to allow gradient computation\n",
        "        g4 = -margin4 # If margin > 0 (satisfied), g < 0. If margin < 0 (violated), g > 0.\n",
        "        g5 = -margin5\n",
        "        g6 = -margin6\n",
        "        # Compute the Lagrangian: L(x, λ) = f(x) + Σ λᵢ * max(0, g_i(x))\n",
        "        # Only apply multipliers when constraints are violated (g > 0)\n",
        "        lagrangian_term4 = self.lambda_cond4 * torch.relu(g4)\n",
        "        lagrangian_term5 = self.lambda_cond5 * torch.relu(g5)\n",
        "        lagrangian_term6 = self.lambda_cond6 * torch.relu(g6)\n",
        "\n",
        "        # Add augmented Lagrangian quadratic terms for better convergence\n",
        "        # These help with numerical stability and convergence\n",
        "        aug_term4 = 0.5 * (torch.relu(g4) ** 2)\n",
        "        aug_term5 = 0.5 * (torch.relu(g5) ** 2)\n",
        "        aug_term6 = 0.5 * (torch.relu(g6) ** 2)\n",
        "\n",
        "        # Total constraint contribution to the Lagrangian\n",
        "        constraint_terms = lagrangian_term4 + lagrangian_term5 + lagrangian_term6 + aug_term4 + aug_term5 + aug_term6\n",
        "\n",
        "        # Total Lagrangian\n",
        "        total_loss = performance_loss + constraint_terms\n",
        "\n",
        "        # Prepare diagnostics for logging\n",
        "        constraint_info = {\n",
        "            \"lambda4\": self.lambda_cond4.item(),\n",
        "            \"lambda5\": self.lambda_cond5.item(),\n",
        "            \"lambda6\": self.lambda_cond6.item(),\n",
        "            \"g4\": g4.item() if hasattr(g4, \"item\") else float(g4),\n",
        "            \"g5\": g5.item() if hasattr(g5, \"item\") else float(g5),\n",
        "            \"g6\": g6.item() if hasattr(g6, \"item\") else float(g6),\n",
        "            \"scenario\": self.scenario\n",
        "        }\n",
        "\n",
        "        return total_loss, performance_loss, constraint_terms, constraint_info\n",
        "\n",
        "    def run_lagrangian_optimization(self, num_epochs=20, learning_rate=0.01, multiplier_step_size=0.1):\n",
        "        \"\"\"\n",
        "        Run optimization using the Lagrangian method.\n",
        "        Original implementation for a single scenario.\n",
        "        \"\"\"\n",
        "        # Create optimizer for primal variables (controller parameters)\n",
        "        # We exclude Lagrange multipliers from the main optimization\n",
        "        primal_params = [p for name, p in self.named_parameters()\n",
        "                         if not name.startswith('lambda_')]\n",
        "        optimizer = torch.optim.Adam(primal_params, lr=learning_rate)\n",
        "\n",
        "        # Initialize constraint cache\n",
        "        self.initialize_constraint_cache()\n",
        "\n",
        "        # Track losses and constraint satisfaction\n",
        "        losses = []\n",
        "        constraint_satisfaction = []\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Step 1: Optimize primal variables (controller parameters)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Run simulation with the selected scenario\n",
        "            t_vec, sol = self.run_simulation_for_scenario(self.scenario)\n",
        "\n",
        "            # Compute Lagrangian loss\n",
        "            total_loss, perf_loss, constraint_terms, constraint_info = self.compute_lagrangian_loss(t_vec, sol)\n",
        "            losses.append(total_loss.item())\n",
        "\n",
        "            # Backpropagate\n",
        "            total_loss.backward()\n",
        "\n",
        "            # Update primal variables\n",
        "            optimizer.step()\n",
        "\n",
        "            # Project parameters to physical bounds if needed\n",
        "            self.project_parameters()\n",
        "\n",
        "            # Step 2: Update Lagrange multipliers\n",
        "            self.update_lagrange_multipliers(step_size=multiplier_step_size)\n",
        "\n",
        "            # Check constraint satisfaction\n",
        "            stability_results = self.check_stability_conditions()\n",
        "            all_satisfied = stability_results[\"all_satisfied\"]\n",
        "            constraint_satisfaction.append(all_satisfied)\n",
        "\n",
        "            # Report progress\n",
        "            if epoch % 1 == 0:\n",
        "                print(f\"Epoch {epoch}: Total Loss={total_loss.item():.6f}, Performance Loss={perf_loss.item():.6f}\")\n",
        "                print(f\"  Lagrange multipliers: λ4={constraint_info['lambda4']:.4f}, λ5={constraint_info['lambda5']:.4f}, λ6={constraint_info['lambda6']:.4f}\")\n",
        "                print(f\"  Constraint values: g4={constraint_info['g4']:.6f}, g5={constraint_info['g5']:.6f}, g6={constraint_info['g6']:.6f}\")\n",
        "                print(f\"  All constraints satisfied: {all_satisfied}\")\n",
        "                print(f\"  Parameters: eta={self.eta.item():.4f}, eta_a={self.eta_a.item():.4f}, Kp_v={self.Kp_v.item():.4f}, Ki_v={self.Ki_v.item():.4f}, Kp_f={self.Kp_f.item():.4f}, Ki_f={self.Ki_f.item():.4f}\")\n",
        "\n",
        "        # Final constraint check\n",
        "        final_stability = self.check_stability_conditions(verbose=True)\n",
        "        print(f\"Final constraint satisfaction: {final_stability['all_satisfied']}\")\n",
        "\n",
        "        return losses, constraint_satisfaction\n",
        "    def run_multi_scenario_optimization(\n",
        "            self, num_epochs=20, learning_rate=0.05, multiplier_step_size=0.1):\n",
        "\n",
        "        # ---------------------------------------------------------------\n",
        "        # 1.  scenarios & weights\n",
        "        scenarios = [\"load_change\"]\n",
        "        scenario_weights = dict.fromkeys(scenarios, 1.0 / len(scenarios))\n",
        "        print(f\"Using scenario weights (for logging only): {scenario_weights}\")\n",
        "\n",
        "        # ---------------------------------------------------------------\n",
        "        # 2.  wrap Adam with PCGrad\n",
        "        primal_params = [p for n, p in self.named_parameters()\n",
        "                        if not n.startswith('lambda_')]\n",
        "        inner_optim   = torch.optim.Adam(primal_params, lr=learning_rate)\n",
        "        optimizer     = PCGrad(inner_optim)          # <-- projection step\n",
        "\n",
        "        # bookkeeping\n",
        "        all_losses            = []\n",
        "        per_scenario_losses   = {s: [] for s in scenarios}\n",
        "        constraint_satisfaction = []\n",
        "        initial_params = { 'eta': self.eta.item(),\n",
        "                          'eta_a': self.eta_a.item(),\n",
        "                          'Kp_v': self.Kp_v.item(),\n",
        "                          'Ki_v': self.Ki_v.item(),\n",
        "                          'Kp_f': self.Kp_f.item(),\n",
        "                          'Ki_f': self.Ki_f.item(), }\n",
        "\n",
        "        # ---------------------------------------------------------------\n",
        "        for epoch in range(num_epochs):\n",
        "            optimizer.zero_grad()\n",
        "            task_losses, task_scalars = {}, {}\n",
        "\n",
        "            for scen in scenarios:\n",
        "                t_vec, sol = self.run_simulation_for_scenario(scen)\n",
        "                loss, *_   = self.compute_lagrangian_loss(t_vec, sol)\n",
        "                task_losses[scen]  = loss\n",
        "                task_scalars[scen] = loss.item()\n",
        "                per_scenario_losses[scen].append(loss.item())\n",
        "\n",
        "            # ---------- PCGrad projection & step -----------------------\n",
        "            optimizer.pc_backward([task_losses[s] for s in scenarios])\n",
        "            with torch.no_grad():\n",
        "                pg = {s: torch.cat([p.grad.view(-1) for p in primal_params])\n",
        "                      for s in scenarios}\n",
        "            #    cos = torch.nn.functional.cosine_similarity(pg['load_change'],\n",
        "             #                                               pg['setpoint_change'], dim=0)\n",
        "              #  print(f\"  cosine(load, setpoint) after PCGrad = {cos.item():+.3f}\")\n",
        "#\n",
        "            optimizer.step()\n",
        "\n",
        "            # ---- project controller parameters to bounds -------------\n",
        "            self.project_parameters()\n",
        "\n",
        "            # ---- update multipliers ----------------------------------\n",
        "            self.update_lagrange_multipliers(step_size=multiplier_step_size)\n",
        "\n",
        "            # ---- record combined loss (weighted sum for the plot) ----\n",
        "            combined_loss = sum(scenario_weights[s] * task_losses[s]\n",
        "                                for s in scenarios)\n",
        "            all_losses.append(combined_loss.item())\n",
        "\n",
        "            # ---- constraint check & logging --------------------------\n",
        "            stab = self.check_stability_conditions()\n",
        "            constraint_satisfaction.append(stab[\"all_satisfied\"])\n",
        "\n",
        "            if epoch % 1 == 0:\n",
        "                print(f\"Epoch {epoch}: combined={combined_loss.item():.6f} \")\n",
        "            #          f\"| load={task_scalars['load_change']:.6f} \"\n",
        "             #         f\"| λ4,5,6=({self.lambda_cond4.item():.3f}, \"\n",
        "             #         f\"{self.lambda_cond5.item():.3f}, \"\n",
        "               #       f\"{self.lambda_cond6.item():.3f}) \"\n",
        "               #       f\"| constraints ok? {stab['all_satisfied']}\")\n",
        "                print(f\"  Parameters: eta={self.eta.item():.4f}, eta_a={self.eta_a.item():.4f}, Kp_v={self.Kp_v.item():.4f}, Ki_v={self.Ki_v.item():.4f}, Kp_f={self.Kp_f.item():.4f}, Ki_f={self.Ki_f.item():.4f}\")\n",
        "\n",
        "#                      f\"| setpt={task_scalars['setpoint_change']:.6f} \"\n",
        "\n",
        "        # Final constraint check (your existing code)\n",
        "        final_stability = self.check_stability_conditions(verbose=True)\n",
        "        print(f\"Final constraint satisfaction: {final_stability['all_satisfied']}\")\n",
        "\n",
        "        # Report parameter changes (your existing code)\n",
        "        print(\"\\nParameter changes from initial values:\")\n",
        "        print(f\"  eta: {initial_params['eta']:.4f} -> {self.eta.item():.4f} ({(self.eta.item() - initial_params['eta'])/initial_params['eta']*100:.1f}%)\")\n",
        "        print(f\"  eta_a: {initial_params['eta_a']:.4f} -> {self.eta_a.item():.4f} ({(self.eta_a.item() - initial_params['eta_a'])/initial_params['eta_a']*100:.1f}%)\")\n",
        "        print(f\"  Kp_v: {initial_params['Kp_v']:.4f} -> {self.Kp_v.item():.4f} ({(self.Kp_v.item() - initial_params['Kp_v'])/initial_params['Kp_v']*100:.1f}%)\")\n",
        "        print(f\"  Ki_v: {initial_params['Ki_v']:.4f} -> {self.Ki_v.item():.4f} ({(self.Ki_v.item() - initial_params['Ki_v'])/initial_params['Ki_v']*100:.1f}%)\")\n",
        "        print(f\"  Kp_f: {initial_params['Kp_f']:.4f} -> {self.Kp_f.item():.4f} ({(self.Kp_f.item() - initial_params['Kp_f'])/initial_params['Kp_f']*100:.1f}%)\")\n",
        "        print(f\"  Ki_f: {initial_params['Ki_f']:.4f} -> {self.Ki_f.item():.4f} ({(self.Ki_f.item() - initial_params['Ki_f'])/initial_params['Ki_f']*100:.1f}%)\")\n",
        "\n",
        "        # Plot the optimization progress\n",
        "        self.plot_optimization_progress(all_losses, per_scenario_losses)\n",
        "\n",
        "        return all_losses, per_scenario_losses, constraint_satisfaction\n",
        "    def plot_optimization_progress(self, combined_losses, per_scenario_losses):\n",
        "        \"\"\"Plot the optimization progress\"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Plot combined loss\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(combined_losses, 'k-', linewidth=2, label='Combined Loss')\n",
        "        plt.title('Multi-Scenario Optimization Progress')\n",
        "        plt.ylabel('Combined Loss')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "\n",
        "        # Plot per-scenario losses\n",
        "        plt.subplot(2, 1, 2)\n",
        "        colors = {'black_start': 'b', 'load_change': 'r', 'setpoint_change': 'g', 'disturbance': 'm'}\n",
        "        for scenario, losses in per_scenario_losses.items():\n",
        "            plt.plot(losses, color=colors[scenario], label=scenario.replace('_', ' ').title())\n",
        "\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def process_and_plot_scenario_results(self, t_vec, sol):\n",
        "        \"\"\"Process and plot results with scenario-specific information\"\"\"\n",
        "        results = self.process_results(t_vec, sol)\n",
        "\n",
        "        # Plot with scenario information\n",
        "        fig, axes = plt.subplots(4, 1, figsize=(10, 12), sharex=True)\n",
        "\n",
        "        scenario_title = {\n",
        "            'black_start': 'Black Start Scenario',\n",
        "            'load_change': f'Load Change Scenario (rL: {self.network.rL:.2f}Ω)',\n",
        "            'setpoint_change': 'Setpoint Change Scenario',\n",
        "            'disturbance': f'Disturbance Scenario (at t={self.disturbance_time}s)'\n",
        "        }\n",
        "\n",
        "        fig.suptitle(scenario_title.get(self.scenario, 'Simulation Results'), fontsize=16)\n",
        "\n",
        "        # Frequencies\n",
        "        for i in range(self.network.Nc):\n",
        "            axes[0].plot(t_vec, results['frequency'][:, i], label=f'Conv {i+1}')\n",
        "        axes[0].set_ylabel('Frequency (Hz)')\n",
        "        axes[0].set_title('System Frequencies')\n",
        "        axes[0].grid(True)\n",
        "        axes[0].legend()\n",
        "\n",
        "        # Voltage magnitudes\n",
        "        for i in range(self.network.Nc):\n",
        "            axes[1].plot(t_vec, results['voltage_mag'][:, i], label=f'Conv {i+1}')\n",
        "        axes[1].set_ylabel('Voltage (V)')\n",
        "        axes[1].set_title('Voltage Magnitudes')\n",
        "        axes[1].grid(True)\n",
        "        axes[1].legend()\n",
        "\n",
        "        # Active power\n",
        "        for i in range(self.network.Nc):\n",
        "            axes[2].plot(t_vec, results['active_power'][:, i], label=f'Conv {i+1}')\n",
        "        axes[2].set_ylabel('Active Power (W)')\n",
        "        axes[2].set_title('Active Power')\n",
        "        axes[2].grid(True)\n",
        "        axes[2].legend()\n",
        "\n",
        "        # Reactive power\n",
        "        for i in range(self.network.Nc):\n",
        "            axes[3].plot(t_vec, results['reactive_power'][:, i], label=f'Conv {i+1}')\n",
        "        axes[3].set_ylabel('Reactive Power (VAr)')\n",
        "        axes[3].set_xlabel('Time (s)')\n",
        "        axes[3].set_title('Reactive Power')\n",
        "        axes[3].grid(True)\n",
        "        axes[3].legend()\n",
        "\n",
        "        # Mark disturbance time if applicable\n",
        "        if self.scenario == 'disturbance':\n",
        "            for ax in axes:\n",
        "                ax.axvline(x=self.disturbance_time, color='r', linestyle='--', alpha=0.5)\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.95])  # Make room for the suptitle\n",
        "        plt.show()\n",
        "\n",
        "        return results\n",
        "\n",
        "    # The system_equations and other methods remain unchanged\n",
        "    def system_equationsx(self, t, state):\n",
        "        \"\"\"Alias kept for Newton–solver compatibility (uses full line ODE).\"\"\"\n",
        "        return self.system_equations_differential(t, state)\n",
        "    def compute_loss(self, t_vec, sol):\n",
        "        \"\"\"\n",
        "        Compute performance loss using L-infinity norm (maximum deviation)\n",
        "        of voltage magnitudes from v* = 120V setpoint.\n",
        "        \"\"\"\n",
        "        # Basic sanity check first\n",
        "        if sol is None:\n",
        "            print(f\"WARNING: Simulation returned None. Assigning high penalty loss.\")\n",
        "            large_loss = torch.tensor(1e6, dtype=self.dtype, device=self.device)\n",
        "            return large_loss\n",
        "\n",
        "        # Handle dimensions with/without line currents\n",
        "        Nc, Nt = self.network.Nc, self.network.Nt\n",
        "        n_conv, n_line = 2 * Nc, 2 * Nt\n",
        "\n",
        "        # Standardize state vector (remove line currents if present)\n",
        "        if self.integrate_line_dynamics:\n",
        "            # Format: [vhat, i_line, v, zeta_v, i_f, zeta_f]\n",
        "            vhat_indices = slice(0, n_conv)\n",
        "            v_indices = slice(n_conv + n_line, 2*n_conv + n_line)\n",
        "        else:\n",
        "            # Format: [vhat, v, zeta_v, i_f, zeta_f]\n",
        "            vhat_indices = slice(0, n_conv)\n",
        "            v_indices = slice(n_conv, 2*n_conv)\n",
        "\n",
        "        # Extract voltage components\n",
        "        vhat_sol = sol[:, vhat_indices].reshape(-1, Nc, 2)  # reshape to [time, converters, αβ]\n",
        "        v_sol = sol[:, v_indices].reshape(-1, Nc, 2)       # reshape to [time, converters, αβ]\n",
        "\n",
        "        # Get voltage setpoints\n",
        "        v_star = self.converter.setpoints.v_star  # [Nc]\n",
        "\n",
        "        # Compute voltage magnitudes\n",
        "        vhat_mag_sol = torch.norm(vhat_sol, dim=2)  # [time, Nc]\n",
        "        v_mag_sol = torch.norm(v_sol, dim=2)        # [time, Nc]\n",
        "\n",
        "        # Calculate magnitude deviations directly from v*\n",
        "        vhat_dev = (vhat_mag_sol - v_star.unsqueeze(0)) / v_star.unsqueeze(0)\n",
        "        v_dev = (v_mag_sol - v_star.unsqueeze(0)) / v_star.unsqueeze(0)\n",
        "\n",
        "        # Calculate L-infinity norm (maximum absolute deviation)\n",
        "        vhat_loss = torch.mean(torch.abs(vhat_dev))\n",
        "        v_loss = torch.mean(torch.abs(v_dev))\n",
        "\n",
        "        # Add peak oscillation measure for latter part of simulation\n",
        "        num_steps = sol.shape[0]\n",
        "        latter_half_idx = num_steps // 2\n",
        "        v_mag_latter = v_mag_sol[latter_half_idx:, :]\n",
        "\n",
        "        # Maximum peak-to-peak deviation for each converter in latter half\n",
        "        peak_to_peak = torch.max(v_mag_latter, dim=0)[0] - torch.min(v_mag_latter, dim=0)[0]\n",
        "        oscillation_penalty = torch.max(peak_to_peak) / torch.mean(v_star)\n",
        "\n",
        "        # Weight components (emphasize terminal voltage v over reference vhat)\n",
        "        total_loss = 3.0 * vhat_loss + 10.0 * v_loss\n",
        "\n",
        "        # Ensure we maintain gradients\n",
        "        if sol.requires_grad and not total_loss.requires_grad:\n",
        "            total_loss = total_loss + 0.0 * sol.sum()\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    def check_stability_conditions(self, verbose=False):\n",
        "        \"\"\"Check all three stability conditions and return results.\"\"\"\n",
        "        cond4 = self.check_condition4()\n",
        "        cond5 = self.check_condition5()\n",
        "        cond6 = self.check_condition6()\n",
        "\n",
        "        all_satisfied = cond4['satisfied'] and cond5['satisfied'] and cond6['satisfied']\n",
        "        min_margin = min(cond4['margin'], cond5['margin'], cond6['margin'])\n",
        "\n",
        "        results = {\n",
        "            \"condition4\": cond4,\n",
        "            \"condition5\": cond5,\n",
        "            \"condition6\": cond6,\n",
        "            \"all_satisfied\": all_satisfied,\n",
        "            \"min_margin\": min_margin\n",
        "        }\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Stability Conditions Check:\")\n",
        "            print(f\"  Condition 4: {'✓' if cond4['satisfied'] else '✗'} (margin: {cond4['margin']:.6f}, rhs: {cond4['rhs']:.6f})\")\n",
        "            print(f\"  Condition 5: {'✓' if cond5['satisfied'] else '✗'} (lhs: {cond5['lhs']:.6f}, rhs: {cond5['rhs']:.6f}, margin: {cond5['margin']:.6f})\")\n",
        "            print(f\"  Condition 6: {'✓' if cond6['satisfied'] else '✗'} (lhs: {cond6['lhs']:.6f}, rhs: {cond6['rhs']:.6f}, margin: {cond6['margin']:.6f})\")\n",
        "            print(f\"  All conditions satisfied: {'✓' if all_satisfied else '✗'} (min margin: {min_margin:.6f})\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def project_parameters(self):\n",
        "        \"\"\"\n",
        "        Project controller parameters to stay within safe bounds.\n",
        "        For example, ensure Ki_v > cf and Ki_f > lf.\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            eta_min, eta_max = 0.1, 100.0\n",
        "            eta_a_min, eta_a_max = 0.1, 100.0\n",
        "            Kp_v_min, Kp_v_max = 0.01, 10.0\n",
        "            Ki_v_min, Ki_v_max = 0.01, 10.0\n",
        "            Kp_f_min, Kp_f_max = 0.1, 100.0\n",
        "            Ki_f_min, Ki_f_max = 0.1, 200.0\n",
        "            self.eta.data.clamp_(eta_min, eta_max)\n",
        "            self.eta_a.data.clamp_(eta_a_min, eta_a_max)\n",
        "            self.Kp_v.data.clamp_(Kp_v_min, Kp_v_max)\n",
        "            self.Ki_v.data.clamp_(Ki_v_min, Ki_v_max)\n",
        "            self.Kp_f.data.clamp_(Kp_f_min, Kp_f_max)\n",
        "            self.Ki_f.data.clamp_(Ki_f_min, Ki_f_max)\n",
        "            # Enforce Ki_v > cf and Ki_f > lf with a small margin.\n",
        "            self.Ki_v.data.clamp_(min=self.converter.cf * 1.01)\n",
        "            self.Ki_f.data.clamp_(min=self.converter.lf * 1.01)\n",
        "\n",
        "    # The condition check methods remain the same\n",
        "    def check_condition4(self):\n",
        "        c_L, p_star_max, v_star_min, d_max = self.compute_cL()\n",
        "        rho = self.network.lt / self.network.rt\n",
        "        constant_term = 5 * (p_star_max / v_star_min) + 10 * d_max\n",
        "        rhs4 = c_L / (2 * rho * d_max * (c_L + constant_term))\n",
        "        tol = 1e-6\n",
        "        margin = rhs4 - self.eta + tol\n",
        "        satisfied = (self.eta < rhs4 + tol)\n",
        "        return {'satisfied': satisfied, 'margin': margin, 'rhs': rhs4}\n",
        "\n",
        "    def check_condition5(self):\n",
        "        ratio1 = self.converter.Ki_v / self.converter.Kp_v\n",
        "        ratio2 = self.converter.Ki_v / self.converter.cf\n",
        "        if torch.any(ratio2 <= 1):\n",
        "            return {'satisfied': False, 'margin': -float('inf'), 'lhs': None, 'rhs': None}\n",
        "        lhs = (1 + torch.max(ratio1)) / (torch.min(ratio2) - 1)\n",
        "        c2 = self.linearize_voltage_dynamics(idx=0)\n",
        "        norm_BR = self.compute_norm_BR()\n",
        "        rhs = 4 * self.eta * c2 / (norm_BR * (1 + 4 * self.eta**2))\n",
        "        tol = 1e-2\n",
        "        margin = rhs - lhs + tol\n",
        "        satisfied = (lhs < rhs + tol)\n",
        "        return {'satisfied': satisfied, 'margin': margin, 'lhs': lhs, 'rhs': rhs}\n",
        "\n",
        "    def check_condition6(self):\n",
        "        ratio3 = self.converter.Ki_f / self.converter.Kp_f\n",
        "        ratio4 = self.converter.Ki_f / self.converter.lf\n",
        "        if torch.any(ratio4 <= 1):\n",
        "            return {'satisfied': False, 'margin': -float('inf'), 'lhs': None, 'rhs': None}\n",
        "        lhs = (1 + torch.max(ratio3))/ (torch.min(ratio4) - 1)\n",
        "\n",
        "        beta34 = (1.0 / self.converter.Ki_v + 1.0 / self.converter.Kp_v).max()\n",
        "        avg_Kp_v = self.converter.Kp_v.mean()\n",
        "        beta_tilde42 = self.network.omega0 / math.sin(self.network.kappa) + self.eta* avg_Kp_v\n",
        "        norm_Yf = torch.norm(self.converter.Yf)\n",
        "        norm_Kp_v = torch.norm(self.converter.Kp_v)\n",
        "        norm_BR = self.compute_norm_BR()\n",
        "        beta_tilde43 = norm_Yf + norm_Kp_v + norm_BR + self.converter.Ki_v.max()\n",
        "        beta_tilde41 = avg_Kp_v\n",
        "        beta_tilde_gamma4 = 0.0  # Assume negligible\n",
        "        beta_squared = beta_tilde41**2 + beta_tilde42**2 + 4 * (beta_tilde43**2)\n",
        "\n",
        "        c3 = self.linearize_current_dynamics(idx=0)\n",
        "        denominator = beta34 * beta_squared + c3 * beta_tilde_gamma4\n",
        "        rhs = 4 * c3 / (denominator + 1e-6)\n",
        "        tol = 1e-2\n",
        "        margin = rhs - lhs + tol\n",
        "        satisfied = (lhs < rhs + tol)\n",
        "        return {'satisfied': satisfied, 'margin': margin, 'lhs': lhs, 'rhs': rhs}\n",
        "\n",
        "    # Support methods remain the same\n",
        "    def compute_cL(self):\n",
        "        v_star_squared = self.converter.setpoints.v_star ** 2\n",
        "        p_star_squared = self.converter.setpoints.p_star ** 2 + self.converter.setpoints.q_star ** 2\n",
        "        p_star_max = torch.max(p_star_squared)\n",
        "        v_star_min = torch.min(v_star_squared)\n",
        "        d_max = self.compute_network_constants()\n",
        "        c_L = v_star_min / d_max\n",
        "        return c_L, p_star_max, v_star_min, d_max\n",
        "\n",
        "    def compute_network_constants(self):\n",
        "        rt = self.network.rt\n",
        "        lt = self.network.lt\n",
        "        omega0 = self.network.omega0\n",
        "        rt_tensor = torch.tensor(rt, device=self.device, dtype=self.dtype)\n",
        "        lt_tensor = torch.tensor(lt, device=self.device, dtype=self.dtype)\n",
        "        omega0_tensor = torch.tensor(omega0, device=self.device, dtype=self.dtype)\n",
        "        Y_branch = 1.0 / torch.sqrt(rt_tensor**2 + (omega0_tensor * lt_tensor)**2)\n",
        "        ones_vec = torch.ones(self.network.Nt * 2, device=self.device, dtype=self.dtype)\n",
        "        Y_diag = torch.diag(Y_branch * ones_vec)\n",
        "        norm_val = torch.norm(self.network.B @ Y_diag @ self.network.B.T)\n",
        "        return norm_val\n",
        "\n",
        "    def compute_norm_BR(self):\n",
        "        if \"norm_BR\" in self._constraint_cache and self._constraint_cache[\"norm_BR\"] is not None:\n",
        "            return self._constraint_cache[\"norm_BR\"]\n",
        "\n",
        "        ones_vec = torch.ones(self.network.Nt * 2, device=self.device, dtype=self.dtype)\n",
        "        Rt_inv = torch.diag(ones_vec / self.network.rt)\n",
        "        norm_val = torch.norm(self.network.B @ Rt_inv @ self.network.B.T)\n",
        "\n",
        "        self._constraint_cache[\"norm_BR\"] = norm_val\n",
        "        return norm_val\n",
        "\n",
        "    def linearize_voltage_dynamics(self, idx, eps=1e-5):\n",
        "        if \"c2\" in self._constraint_cache and self._constraint_cache[\"c2\"] is not None:\n",
        "            return self._constraint_cache[\"c2\"]\n",
        "\n",
        "        setpoints = self.converter.setpoints\n",
        "        v_eq = torch.tensor([setpoints.v_star[idx], 0.0], dtype=self.dtype, device=self.device)\n",
        "        def voltage_error_func(vhat_pert):\n",
        "            vhat = v_eq + vhat_pert\n",
        "            i_line = torch.zeros(2 * self.network.Nt, dtype=self.dtype, device=self.device)\n",
        "            zeta_v = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "            v_full = v_eq.repeat(self.network.Nc)\n",
        "            dvhat, _ = self.converter.voltage_control(idx, v_eq, vhat, i_line, zeta_v, v_full, setpoints)\n",
        "            return dvhat\n",
        "        x0 = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "        J_v = torch.autograd.functional.jacobian(voltage_error_func, x0, vectorize=True,create_graph=True)\n",
        "        eigenvals = torch.linalg.eigvals(-J_v)\n",
        "        c2 = eigenvals.real.min()\n",
        "\n",
        "        self._constraint_cache[\"c2\"] = c2\n",
        "        return c2\n",
        "\n",
        "    def linearize_current_dynamics(self, idx, eps=1e-5):\n",
        "        if \"c3\" in self._constraint_cache and self._constraint_cache[\"c3\"] is not None:\n",
        "            return self._constraint_cache[\"c3\"]\n",
        "\n",
        "        setpoints = self.converter.setpoints\n",
        "        v_eq = torch.tensor([setpoints.v_star[idx], 0.0], dtype=self.dtype, device=self.device)\n",
        "        i_eq = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "        def current_error_func(i_pert):\n",
        "            i_f = i_eq + i_pert\n",
        "            zeta_f = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "            i_ref = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "            vm, _ = self.converter.current_control(idx, v_eq, i_f, i_ref, zeta_f)\n",
        "            return vm\n",
        "        x0 = torch.zeros(2, dtype=self.dtype, device=self.device)\n",
        "        J_c = torch.autograd.functional.jacobian(current_error_func, x0, vectorize=True,create_graph=True)\n",
        "        eigenvals = torch.linalg.eigvals(-J_c)\n",
        "        c3 = eigenvals.real.min()\n",
        "\n",
        "        self._constraint_cache[\"c3\"] = c3\n",
        "        return c3\n",
        "\n",
        "    def run_simulation(self):\n",
        "        \"\"\"\n",
        "        Run the actual numerical simulation using odeint.\n",
        "        This method sets up the time stepping and initial conditions,\n",
        "        then calls the ODE solver.\n",
        "        \"\"\"\n",
        "        steps = int(self.T_sim / self.dt) + 1\n",
        "        t_span = torch.linspace(\n",
        "            0.0, self.T_sim, steps, dtype=self.dtype, device=self.device\n",
        "        )\n",
        "        x0 = self.initialize_black_start()\n",
        "\n",
        "        # Remove rtol/atol from options since they're passed directly\n",
        "        sol = odeint(\n",
        "                    func=self,\n",
        "                    y0=x0,\n",
        "                    t=t_span,\n",
        "                    method='radau',\n",
        "                    rtol=1e-3,\n",
        "                    atol=1e-3,)\n",
        "      #  sol=odeint_adjoint(self,x0, t_span, method=\"scipy_solver\", options={\"solver\": 'BDF'})\n",
        "\n",
        "        return t_span, sol\n",
        "\n",
        "    def map_states_with_algebraic_line_currents(self, state_with_i_line):\n",
        "        \"\"\"\n",
        "        Maps a state vector with line currents to a state vector without line currents\n",
        "        by computing the line currents algebraically.\n",
        "\n",
        "        Input:\n",
        "            state_with_i_line: State vector with format [vhat, i_line, v, zeta_v, i_f, zeta_f]\n",
        "\n",
        "        Returns:\n",
        "            state_without_i_line: State vector with format [vhat, v, zeta_v, i_f, zeta_f]\n",
        "        \"\"\"\n",
        "        Nc = self.network.Nc\n",
        "        n_conv = 2 * Nc\n",
        "        n_line = 2 * self.network.Nt\n",
        "\n",
        "        # Extract all states from the full state vector\n",
        "        vhat = state_with_i_line[0:n_conv]\n",
        "        # i_line is not needed since we'll compute it algebraically\n",
        "        v = state_with_i_line[n_conv+n_line:2*n_conv+n_line]\n",
        "        zeta_v = state_with_i_line[2*n_conv+n_line:3*n_conv+n_line]\n",
        "        i_f = state_with_i_line[3*n_conv+n_line:4*n_conv+n_line]\n",
        "        zeta_f = state_with_i_line[4*n_conv+n_line:5*n_conv+n_line]\n",
        "\n",
        "        # Create the state vector without line currents\n",
        "        state_without_i_line = torch.cat([vhat, v, zeta_v, i_f, zeta_f], dim=0)\n",
        "\n",
        "        return state_without_i_line\n",
        "\n",
        "    def map_states_with_differential_line_currents(self, state_without_i_line):\n",
        "        \"\"\"\n",
        "        Maps a state vector without line currents to a state vector with line currents\n",
        "        by computing the line currents algebraically and inserting them.\n",
        "\n",
        "        Input:\n",
        "            state_without_i_line: State vector with format [vhat, v, zeta_v, i_f, zeta_f]\n",
        "\n",
        "        Returns:\n",
        "            state_with_i_line: State vector with format [vhat, i_line, v, zeta_v, i_f, zeta_f]\n",
        "        \"\"\"\n",
        "        Nc = self.network.Nc\n",
        "        n_conv = 2 * Nc\n",
        "\n",
        "        # Extract states from the reduced state vector\n",
        "        vhat = state_without_i_line[0:n_conv]\n",
        "        v = state_without_i_line[n_conv:2*n_conv]\n",
        "        zeta_v = state_without_i_line[2*n_conv:3*n_conv]\n",
        "        i_f = state_without_i_line[3*n_conv:4*n_conv]\n",
        "        zeta_f = state_without_i_line[4*n_conv:5*n_conv]\n",
        "\n",
        "        # Compute line currents algebraically\n",
        "        i_line, v_common = self.network.compute_algebraic_line_currents(v)\n",
        "\n",
        "        # Create the full state vector with line currents\n",
        "        state_with_i_line = torch.cat([vhat, i_line, v, zeta_v, i_f, zeta_f], dim=0)\n",
        "        return state_with_i_line\n",
        "\n",
        "            # ------------------------------------------------------------------\n",
        "    def compute_equilibrium_point(self, t_steady_val=0.0, x0_guess=None):\n",
        "        \"\"\"\n",
        "        Returns an equilibrium state tensor that satisfies dx/dt ≈ 0\n",
        "        for the CURRENT load rL and the converter set‑points active at\n",
        "        time t_steady_val.  If Newton fails, returns None.\n",
        "        \"\"\"\n",
        "        t_steady = torch.tensor(t_steady_val, dtype=self.dtype, device=self.device)\n",
        "\n",
        "        # ---------- prepare initial guess --------------------------------------\n",
        "        if x0_guess is None:\n",
        "            x0_guess_tensor = self.initialize_from_equilibrium()\n",
        "            x0_guess_tensor = self.map_states_with_differential_line_currents(\n",
        "                                  x0_guess_tensor)                # bug‑fix line\n",
        "            x0_guess = x0_guess_tensor.cpu().numpy()\n",
        "        elif isinstance(x0_guess, torch.Tensor):\n",
        "            x0_guess = self.map_states_with_differential_line_currents(\n",
        "                          x0_guess).cpu().numpy()\n",
        "        # else: already numpy\n",
        "\n",
        "        # ---------- residual function -----------------------------------------\n",
        "        def F(x_np):\n",
        "            x_t = torch.as_tensor(x_np, dtype=self.dtype, device=self.device)\n",
        "            with torch.no_grad():\n",
        "                dx = self.system_equationsx(t_steady, x_t)\n",
        "            return dx.cpu().numpy()\n",
        "\n",
        "        # ---------- call robust Newton ----------------------------------------\n",
        "        x_eq_np, ok, residual, msg = super_safe_solve(F, x0_guess)\n",
        "        print(msg)\n",
        "        if not ok:\n",
        "            print(f\"[equilibrium] fsolve failed (msg='{msg.strip()}', \"\n",
        "                  f\"‖F‖={residual:.3e})\")\n",
        "            return None\n",
        "\n",
        "        x_eq = torch.as_tensor(x_eq_np, dtype=self.dtype, device=self.device)\n",
        "        # convert back to algebraic‑line‑current layout\n",
        "        return (x_eq)\n",
        "\n",
        "\n",
        "\n",
        "    def process_results(self, t_vec, sol):\n",
        "        \"\"\"\n",
        "        Process the raw solution arrays to extract converter voltages, frequencies, etc.\n",
        "        This replicates your approach: we keep track of v, i_f, etc.\n",
        "        \"\"\"\n",
        "        Nc = self.network.Nc\n",
        "        Nt = self.network.Nt\n",
        "        n_conv = 2*Nc\n",
        "        n_line = 2*Nt\n",
        "\n",
        "        off_vhat = 0\n",
        "        off_iline = n_conv\n",
        "        off_v = off_iline + n_line\n",
        "        off_zeta_v = off_v + n_conv\n",
        "        off_if = off_zeta_v + n_conv\n",
        "        off_zeta_f = off_if + n_conv\n",
        "\n",
        "        nsamples = sol.shape[0]\n",
        "        voltage_mag = torch.zeros(nsamples, Nc, dtype=self.dtype)\n",
        "        freq = torch.zeros(nsamples, Nc, dtype=self.dtype)\n",
        "        p_out = torch.zeros(nsamples, Nc, dtype=self.dtype)\n",
        "        q_out = torch.zeros(nsamples, Nc, dtype=self.dtype)\n",
        "\n",
        "        # We'll track the previous voltage for approximate freq\n",
        "        prev_v = torch.zeros(n_conv, dtype=self.dtype)\n",
        "\n",
        "        dt = self.dt\n",
        "        for k in range(nsamples):\n",
        "            # forced update of scenario states\n",
        "            self.state_handler.update_states(float(t_vec[k]))\n",
        "\n",
        "            statek = torch.tensor(sol[k,:], dtype=self.dtype)\n",
        "            v_nodes = statek[off_v:off_v + n_conv]\n",
        "            i_line = statek[off_iline:off_iline + n_line]\n",
        "\n",
        "            for i in range(Nc):\n",
        "                idx_slice = slice(2*i, 2*(i+1))\n",
        "                v_local = v_nodes[idx_slice]\n",
        "\n",
        "                # magnitude\n",
        "                voltage_mag[k, i] = torch.norm(v_local)\n",
        "\n",
        "                # approximate derivative for freq\n",
        "                if k > 0:\n",
        "                    dv_local = (v_local - prev_v[idx_slice]) / dt\n",
        "                    # rough approach: derivative of angle => freq\n",
        "                    # angle_new = atan2(...), but for small dt, we do a small approximation\n",
        "                    # You had a rough approach in the snippet\n",
        "                    # We'll do something simpler here:\n",
        "                    # freq = base_freq + delta_angle/(2 pi dt)\n",
        "                    # but a robust approach requires a proper PLL or angle extraction\n",
        "                    freq[k, i] = self.network.omega0/(2.0*math.pi)  # placeholder\n",
        "                else:\n",
        "                    freq[k, i] = self.network.omega0/(2.0*math.pi)\n",
        "\n",
        "                # Current from network\n",
        "                i_total = self.network.calculate_total_currents(v_nodes, i_line)\n",
        "                i_node = i_total[idx_slice]\n",
        "                # sign conventions can matter a lot. We'll replicate snippet:\n",
        "                i_total_node = - (v_local * 0.0)  # snippet had i_f + i_line, we just replicate\n",
        "                # Basic power:\n",
        "                p_out[k, i] = v_local[0]*i_node[0] + v_local[1]*i_node[1]\n",
        "                q_out[k, i] = v_local[0]*i_node[1] - v_local[1]*i_node[0]\n",
        "\n",
        "            prev_v = v_nodes.clone()\n",
        "\n",
        "        return {\n",
        "            'time': t_vec,\n",
        "            'voltage_mag': voltage_mag.cuda().numpy(),\n",
        "            'frequency': freq.cuda().numpy(),\n",
        "            'active_power': p_out.cuda().numpy(),\n",
        "            'reactive_power': q_out.cuda().numpy()\n",
        "        }\n",
        "\n",
        "        return state_with_i_line\n",
        "    def plot_results(self, results):\n",
        "        \"\"\"\n",
        "        Plotting the final waveforms: frequency, voltage, P, Q.\n",
        "        \"\"\"\n",
        "        t_vec = results['time']\n",
        "        fig, axes = plt.subplots(4, 1, figsize=(10, 12), sharex=True)\n",
        "\n",
        "        # Frequencies\n",
        "        for i in range(self.network.Nc):\n",
        "            axes[0].plot(t_vec, results['frequency'][:, i], label=f'Conv {i+1}')\n",
        "        axes[0].set_ylabel('Frequency (Hz)')\n",
        "        axes[0].set_title('System Frequencies')\n",
        "        axes[0].grid(True)\n",
        "        axes[0].legend()\n",
        "\n",
        "        # Voltage magnitudes\n",
        "        for i in range(self.network.Nc):\n",
        "            axes[1].plot(t_vec, results['voltage_mag'][:, i], label=f'Conv {i+1}')\n",
        "        axes[1].set_ylabel('Voltage (V)')\n",
        "        axes[1].set_title('Voltage Magnitudes')\n",
        "        axes[1].grid(True)\n",
        "        axes[1].legend()\n",
        "\n",
        "        # Active power\n",
        "        for i in range(self.network.Nc):\n",
        "            axes[2].plot(t_vec, results['active_power'][:, i], label=f'Conv {i+1}')\n",
        "        axes[2].set_ylabel('Active Power (W)')\n",
        "        axes[2].set_title('Active Power')\n",
        "        axes[2].grid(True)\n",
        "        axes[2].legend()\n",
        "\n",
        "        # Reactive power\n",
        "        for i in range(self.network.Nc):\n",
        "            axes[3].plot(t_vec, results['reactive_power'][:, i], label=f'Conv {i+1}')\n",
        "        axes[3].set_ylabel('Reactive Power (VAr)')\n",
        "        axes[3].set_xlabel('Time (s)')\n",
        "        axes[3].set_title('Reactive Power')\n",
        "        axes[3].grid(True)\n",
        "        axes[3].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def save_results(self, results, filename='black_start_results_torch.npz'):\n",
        "        \"\"\"\n",
        "        Save results to an .npz file (still using NumPy for convenience).\n",
        "        \"\"\"\n",
        "        import numpy as np\n",
        "        np.savez(filename,\n",
        "                 time=results['time'],\n",
        "                 voltage_mag=results['voltage_mag'],\n",
        "                 frequency=results['frequency'],\n",
        "                 active_power=results['active_power'],\n",
        "                 reactive_power=results['reactive_power'])\n",
        "\n",
        "    def initialize_black_start(self):\n",
        "        \"\"\"\n",
        "        Initialize state vector for black start scenario (all zero) with the\n",
        "        line dynamics removed (assumed instantaneous).\n",
        "        New total state dimension = 5*n_conv = 5*(2*Nc)\n",
        "        Layout: [vhat(6), v(6), zeta_v(6), i_f(6), zeta_f(6)]\n",
        "        \"\"\"\n",
        "        Nc = self.network.Nc\n",
        "        n_conv = 2 * Nc\n",
        "        state_size = 5 * n_conv  # removed n_line\n",
        "\n",
        "        x0 = torch.zeros(state_size, dtype=self.dtype, device=self.device)\n",
        "        # (Optionally, you can set initial conditions for vhat etc.)\n",
        "        # For example, initialize vhat for the first two converters:\n",
        "        for i in range(2):\n",
        "            idx_vhat = 2 * i\n",
        "            x0[idx_vhat:idx_vhat+2] = torch.tensor([0.01, 0.0], dtype=self.dtype, device=self.device)\n",
        "        return x0\n",
        "\n",
        "# Main execution block updated to use Lagrangian approach\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    dtype = torch.float64\n",
        "    sim = MultiConverterSimulation(device=device, dtype=dtype)\n",
        "\n",
        "    import random\n",
        "    # Set random seed for reproducibility\n",
        "    random.seed(42)\n",
        "\n",
        "    # Choose operation mode\n",
        "    mode = \"optimize_multi\"  # Options: \"optimize_single\", \"optimize_multi\", \"test\"\n",
        "\n",
        "    if mode == \"optimize_single\":\n",
        "        # Optimize for a single scenario (original approach)\n",
        "        sim.scenario = \"black_start\"  # Choose the scenario to optimize for\n",
        "        print(f\"Running Lagrangian optimization for {sim.scenario} scenario...\")\n",
        "        losses, constraint_satisfaction = sim.run_lagrangian_optimization(\n",
        "            num_epochs=15,\n",
        "            learning_rate=0.01,\n",
        "            multiplier_step_size=0.2\n",
        "        )\n",
        "\n",
        "    elif mode == \"optimize_multi\":\n",
        "        # Optimize across multiple scenarios\n",
        "        print(\"Running multi-scenario optimization...\")\n",
        "        losses, per_scenario_losses, constraint_satisfaction = sim.run_multi_scenario_optimization(\n",
        "            num_epochs=15,\n",
        "            learning_rate=0.05,\n",
        "            multiplier_step_size=0.2\n",
        "        )\n",
        "\n",
        "        print(\"\\nOptimization completed.\")\n",
        "        print(\"Final parameters:\")\n",
        "        print(f\"  eta = {sim.eta.item():.6f}\")\n",
        "        print(f\"  eta_a = {sim.eta_a.item():.6f}\")\n",
        "        print(f\"  Kp_v = {sim.Kp_v.item():.6f}\")\n",
        "        print(f\"  Ki_v = {sim.Ki_v.item():.6f}\")\n",
        "        print(f\"  Kp_f = {sim.Kp_f.item():.6f}\")\n",
        "        print(f\"  Ki_f = {sim.Ki_f.item():.6f}\")\n",
        "\n",
        "    elif mode == \"test\":\n",
        "        # Test with each scenario\n",
        "        scenarios = [\"black_start\", \"load_change\", \"setpoint_change\", \"disturbance\"]\n",
        "\n",
        "        for scenario in scenarios:\n",
        "            print(f\"\\nRunning {scenario} scenario...\")\n",
        "            t_vec, sol = sim.run_simulation_for_scenario(scenario)\n",
        "            sim.process_and_plot_scenario_results(t_vec, sol)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "# 0.  imports & config\n",
        "#######################################################################\n",
        "import torch, math\n",
        "from torchdiffeq import odeint                   # <- adaptive Radau\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device, dtype = 'cpu', torch.float64            # GPU works just as well\n",
        "\n",
        "#######################################################################\n",
        "# 1.  a “wiggly” ODE whose loss surface is strongly non-convex\n",
        "#######################################################################\n",
        "#\n",
        "#     ẋ = p1 · x³  –  x  +  p2 · sin(3t)\n",
        "#     L  = (x(T) – 0.7)²                     <- task performance\n",
        "#        + 0.2·sin(5 p1)² + 0.2·cos(3 p2)²   <- bumpy regulariser\n",
        "#\n",
        "class WigglyODE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.p1 = torch.nn.Parameter(torch.tensor( 0.3, dtype=dtype))   # not at a min\n",
        "        self.p2 = torch.nn.Parameter(torch.tensor(-1.2, dtype=dtype))   #   “   “   ”\n",
        "    def forward(self, t, x):\n",
        "        return (self.p1**3+self.p1**2+self.p1) * x**3 - x + self.p2 * torch.sin(3*t)\n",
        "\n",
        "def simulate_and_loss(model, T=.5):\n",
        "    t  = torch.linspace(0., T, 50, dtype=dtype, device=device)\n",
        "    x0 = torch.tensor([0.25], dtype=dtype, device=device)\n",
        "    x  = odeint(model, x0, t, method='radauIIA5_adaptive',\n",
        "                rtol=1e-6, atol=1e-6)           # same solver you debug\n",
        "    xT = x[-1, 0]\n",
        "    perf = (xT - 0.7)**2\n",
        "    reg  = 0.2*torch.sin(5*model.p1)**2 + 0.2*torch.cos(3*model.p2)**2\n",
        "    return perf + reg\n",
        "\n",
        "#######################################################################\n",
        "# 2.  optimisation loop – watch loss & parameters wander\n",
        "#######################################################################\n",
        "net  = WigglyODE().to(device)\n",
        "opt  = torch.optim.Adam(net.parameters(), lr=0.08, betas=(0.8, 0.99))\n",
        "\n",
        "loss_hist, p1_hist, p2_hist = [], [], []\n",
        "\n",
        "for epoch in range(20):\n",
        "    opt.zero_grad()\n",
        "    L = simulate_and_loss(net)\n",
        "    L.backward()\n",
        "    opt.step()\n",
        "\n",
        "    # record trajectory\n",
        "    loss_hist.append(L.item())\n",
        "    p1_hist.append(net.p1.item())\n",
        "    p2_hist.append(net.p2.item())\n",
        "\n",
        "#######################################################################\n",
        "# 3.  plots\n",
        "#######################################################################\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(loss_hist, label='loss')\n",
        "plt.xlabel('epoch'); plt.ylabel('loss'); plt.title('Non-convex loss trajectory')\n",
        "plt.grid(True); plt.legend()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(p1_hist, label='p1');  plt.plot(p2_hist, label='p2')\n",
        "plt.xlabel('epoch'); plt.ylabel('parameter value')\n",
        "plt.title('Parameter trajectory (note the up-and-down moves)')\n",
        "plt.grid(True); plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "kinUE-1tADQ5",
        "outputId": "cca840ca-3410-4a0c-f809-c83748eb3d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caqtui7GVli-",
        "outputId": "3b8aebee-b325-43b3-9f92-e9d19f4223d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Calculating default equilibrium target …\n",
            "Converged with trf\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 88.25816872 -84.89081752  91.7943647  -67.20780351  88.19850704\n",
            " -85.09822197]…\n"
          ]
        }
      ],
      "source": [
        "            t_vec, sol = sim.run_simulation_for_scenario('load_change')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, deque\n",
        "grad_log = defaultdict(lambda: deque(maxlen=5))   # keeps last 5 signs/means\n",
        "\n",
        "for n, p in sim.named_parameters():\n",
        "    if p.grad is None:\n",
        "        continue\n",
        "    g = p.grad.detach()\n",
        "    mean = g.mean().item()\n",
        "    sign = torch.sign(g)\n",
        "    unique = tuple(sign.unique(sorted=True).tolist())   # e.g. (-1.0,) or (-1.0, 1.0)\n",
        "    grad_log[n].append(sign)\n",
        "\n",
        "    # “flip ratio” = fraction of elements that changed sign vs previous epoch\n",
        "    flip = float('nan')\n",
        "    if len(grad_log[n]) >= 2:\n",
        "        flip = (sign * grad_log[n][-2] < 0).float().mean().item()\n",
        "\n",
        "    print(f\"{n:8s}  ⟨|g|⟩={g.abs().mean():.3e}  sign={unique}  flip={flip:5.1%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39DHUlC2vQ41",
        "outputId": "718cef7e-0258-476d-ba16-1a21cfc31f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eta       ⟨|g|⟩=4.555e+01  sign=(1.0,)  flip= nan%\n",
            "eta_a     ⟨|g|⟩=2.790e-02  sign=(-1.0,)  flip= nan%\n",
            "Kp_v      ⟨|g|⟩=1.602e+03  sign=(-1.0,)  flip= nan%\n",
            "Ki_v      ⟨|g|⟩=1.234e-01  sign=(1.0,)  flip= nan%\n",
            "Kp_f      ⟨|g|⟩=1.215e+02  sign=(-1.0,)  flip= nan%\n",
            "Ki_f      ⟨|g|⟩=2.620e-03  sign=(1.0,)  flip= nan%\n",
            "lambda_cond4  ⟨|g|⟩=1.980e+02  sign=(1.0,)  flip= nan%\n",
            "lambda_cond5  ⟨|g|⟩=0.000e+00  sign=(0.0,)  flip= nan%\n",
            "lambda_cond6  ⟨|g|⟩=0.000e+00  sign=(0.0,)  flip= nan%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPS = 1e-4\n",
        "with torch.no_grad():\n",
        "    for name, p in sim.named_parameters():\n",
        "        if not p.requires_grad or p.grad is None:\n",
        "            continue\n",
        "        # finite-difference along +x\n",
        "        p.data += EPS\n",
        "        t1, s1 = sim.run_simulation_for_scenario(\"load_change\")\n",
        "        L_pos, *_ = sim.compute_lagrangian_loss(t1, s1)\n",
        "        # finite-difference along –x\n",
        "        p.data -= 2*EPS\n",
        "        t2, s2 = sim.run_simulation_for_scenario(\"load_change\")\n",
        "        L_neg, *_ = sim.compute_lagrangian_loss(t2, s2)\n",
        "        # restore\n",
        "        p.data += EPS\n",
        "        num_grad = (L_pos - L_neg) / (2*EPS)\n",
        "        print(f\"{name:8s}   autograd={p.grad.mean():+.3e}   num={num_grad:+.3e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IsYhNjYrwEWp",
        "outputId": "d38c0262-a067-46e5-8416-1c8922cb020e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [84.07152888 89.05764767 66.12661584 92.24106872 84.58154345 88.92408326]…\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [117.22981954 -35.45380271 112.06093214 -17.97592351 117.33685957\n",
            " -35.96357738]…\n",
            "eta        autograd=+4.555e+01   num=+5.277e+01\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [119.05121803 -29.31027172 112.87014884 -11.86834097 119.04349362\n",
            " -29.28749854]…\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [  27.11119548 -119.43436988   39.75008113 -106.30474172   26.71809396\n",
            " -119.7818453 ]…\n",
            "eta_a      autograd=-2.790e-02   num=+2.251e+07\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [  33.35020592 -117.98344123   45.45933681 -103.9901543    33.36660769\n",
            " -117.96505399]…\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-88.38130775 -84.784838   -70.61492965 -88.84997594 -88.87933062\n",
            " -84.62777368]…\n",
            "Kp_v       autograd=-1.602e+03   num=-1.606e+03\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-83.9210815  -89.38435462 -65.68877982 -92.54992122 -83.89716242\n",
            " -89.38886002]…\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-118.22942213   31.96147161 -112.54468599   14.64513298 -118.35181333\n",
            "   32.46900678]…\n",
            "Ki_v       autograd=+1.234e-01   num=-6.911e+00\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-119.8679128    25.76751152 -113.17231301    8.51650234 -119.8595767\n",
            "   25.74517501]…\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-33.50088731 117.80218148 -45.41512357 104.01083947 -33.12808584\n",
            " 118.16930526]…\n",
            "Kp_f       autograd=-1.215e+02   num=-1.244e+02\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-39.65355713 116.0168673  -50.99173787 101.39204189 -39.66882604\n",
            " 115.99775544]…\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [83.61212487 89.48838524 65.65220312 92.57936198 84.12487105 89.35691761]…\n",
            "Ki_f       autograd=+2.620e-03   num=-5.199e+00\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [117.41356777 -34.83452074 112.15597571 -17.38332941 117.52417423\n",
            " -35.34821984]…\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6521cceb8dda>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# finite-difference along –x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_simulation_for_scenario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"load_change\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mL_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_lagrangian_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# restore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-29d62fb02234>\u001b[0m in \u001b[0;36mrun_simulation_for_scenario\u001b[0;34m(self, scenario)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# Setup scenario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_scenario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;31m# Prepare time steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-29d62fb02234>\u001b[0m in \u001b[0;36msetup_scenario\u001b[0;34m(self, scenario)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# (ii) equilibrium for new load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0mprev_eq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario_equilibrium_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_change'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0meq\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_equilibrium_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_steady_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0_guess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_eq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0meq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario_equilibrium_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'load_change'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-29d62fb02234>\u001b[0m in \u001b[0;36mcompute_equilibrium_point\u001b[0;34m(self, t_steady_val, x0_guess)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m         \u001b[0;31m# ---------- call robust Newton ----------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m         \u001b[0mx_eq_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper_safe_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0_guess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-bfd2cc33f2d8>\u001b[0m in \u001b[0;36msuper_safe_solve\u001b[0;34m(F, x0, jac, scale, tol, maxfev, methods, n_multistart, multistart_radius)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"trf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 out = least_squares(\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_jac\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'2-point'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lsq/least_squares.py\u001b[0m in \u001b[0;36mleast_squares\u001b[0;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         result = trf(fun_wrapped, jac_wrapped, x0, f0, J0, lb, ub, ftol, xtol,\n\u001b[0m\u001b[1;32m    948\u001b[0m                      \u001b[0mgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_nfev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m                      tr_options.copy(), verbose)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lsq/trf.py\u001b[0m in \u001b[0;36mtrf\u001b[0;34m(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# functions are kept the most readable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mub\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         return trf_no_bounds(\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_nfev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             loss_function, tr_solver, tr_options, verbose)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lsq/trf.py\u001b[0m in \u001b[0;36mtrf_no_bounds\u001b[0;34m(fun, jac, x0, f0, J0, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m             \u001b[0mnjev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lsq/least_squares.py\u001b[0m in \u001b[0;36mjac_wrapped\u001b[0;34m(x, f)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mjac_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 J = approx_derivative(fun, x, rel_step=diff_step, method=jac,\n\u001b[0m\u001b[1;32m    905\u001b[0m                                       \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                                       kwargs=kwargs, sparsity=jac_sparsity)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             return _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0m\u001b[1;32m    524\u001b[0m                                      use_one_sided, method)\n\u001b[1;32m    525\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Recompute dx as exactly representable number.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3-point'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_one_sided\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             raise RuntimeError(\"`fun` return value has \"\n",
            "\u001b[0;32m<ipython-input-1-bfd2cc33f2d8>\u001b[0m in \u001b[0;36mG\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mg_jac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-29d62fb02234>\u001b[0m in \u001b[0;36mF\u001b[0;34m(x_np)\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m                 \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_equationsx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_steady\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-29d62fb02234>\u001b[0m in \u001b[0;36msystem_equationsx\u001b[0;34m(self, t, state)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msystem_equationsx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;34m\"\"\"Alias kept for Newton–solver compatibility (uses full line ODE).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_equations_differential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m         \"\"\"\n",
            "\u001b[0;32m<ipython-input-8-29d62fb02234>\u001b[0m in \u001b[0;36msystem_equations_differential\u001b[0;34m(self, t, state)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0mdvhat_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdv_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdzeta_v_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdif_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdzeta_f_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             dvh,dv,dzv,dif,dzf = self.converter.compute_converter_dynamics(\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeta_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeta_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m                 self.converter.setpoints, i_line)\n",
            "\u001b[0;32m<ipython-input-8-29d62fb02234>\u001b[0m in \u001b[0;36mcompute_converter_dynamics\u001b[0;34m(self, idx, full_state, setpoints, i_line)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'active'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0;31m# Active\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                 dvhat, dzeta_v_ = self.voltage_control(\n\u001b[0m\u001b[1;32m    555\u001b[0m                     \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvhat_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeta_v_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 )\n",
            "\u001b[0;32m<ipython-input-8-29d62fb02234>\u001b[0m in \u001b[0;36mvoltage_control\u001b[0;34m(self, idx, v_node, vhat_node, i_line, zeta_v_node, v_full, setpoints)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'power_control'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;31m# Full dVOC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mphi_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_Phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvhat_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-29d62fb02234>\u001b[0m in \u001b[0;36mcalculate_K\u001b[0;34m(self, idx, setpoints)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;31m# system-level kappa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mkappa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momega0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         R_kappa = torch.tensor([\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def finite_difference_grad(model, param, eps, scenario=\"load_change\"):\n",
        "    \"\"\"\n",
        "    Central finite difference dL/dθ for ONE scalar parameter tensor (no graph building).\n",
        "    Keeps the cached equilibrium fixed so the surface is identical.\n",
        "    \"\"\"\n",
        "    # helper that reuses the same equilibrium\n",
        "    def forward_only():\n",
        "        model._reuse_equilibrium = True\n",
        "        t_vec, sol = model.run_simulation_for_scenario(scenario)\n",
        "        return model.compute_lagrangian_loss(t_vec, sol)[0].detach()\n",
        "\n",
        "    # baseline loss and param handle\n",
        "    theta = param.data\n",
        "    loss0 = forward_only()\n",
        "\n",
        "    # +eps\n",
        "    theta += eps\n",
        "    loss_plus = forward_only()\n",
        "\n",
        "    # -eps\n",
        "    theta -= 2*eps\n",
        "    loss_minus = forward_only()\n",
        "\n",
        "    # restore\n",
        "    theta += eps\n",
        "    model._reuse_equilibrium = False   # turn it off again\n",
        "    return (loss_plus - loss_minus) / (2*eps)\n",
        "\n",
        "\n",
        "def gradient_check(model, eps=1e-4, verbose=True):\n",
        "    rows = []\n",
        "    model.zero_grad()\n",
        "    # Build graph **once** (will also cache eq.)\n",
        "    t_vec, sol = model.run_simulation_for_scenario(\"load_change\")\n",
        "    total_loss, *_ = model.compute_lagrangian_loss(t_vec, sol)\n",
        "    total_loss.backward()\n",
        "\n",
        "    for name, p in model.named_parameters():\n",
        "        if p.grad is None or p.numel() != 1:    # check only scalars\n",
        "            continue\n",
        "        fd = finite_difference_grad(model, p, eps)\n",
        "        ag = p.grad.detach().clone()\n",
        "        rel_err = ((ag - fd).abs() / (fd.abs() + 1e-12)).item()\n",
        "        agree = \"✓\" if rel_err < 1e-2 or torch.sign(ag) == torch.sign(fd) else \"✗\"\n",
        "        rows.append((name, ag.item(), fd.item(), rel_err, agree))\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"{'name':10s} {'autograd':>12s} {'finite-diff':>12s} {'rel-err':>9s}  agree?\")\n",
        "        for n,a,f,e,s in rows:\n",
        "            print(f\"{n:10s} {a:+12.3e} {f:+12.3e} {e:9.1e}   {s}\")\n",
        "    return rows\n"
      ],
      "metadata": {
        "id": "IWX4luc7x-bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, math\n",
        "from torchdiffeq import odeint\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Toy model and loss  (identical to previous message)\n",
        "# -------------------------------------------------------------------\n",
        "class ToyStiffODE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.p1 = torch.nn.Parameter(torch.tensor(+0.8, dtype=torch.float64))\n",
        "        self.p2 = torch.nn.Parameter(torch.tensor(+1.5, dtype=torch.float64))\n",
        "    def forward(self, t, x):\n",
        "        return self.p1 * x**3 - x + self.p2 * torch.sin(3*t)\n",
        "\n",
        "def forward_sim_and_loss(model, T=2.0, device='cpu'):\n",
        "    t = torch.linspace(0.0, T, 401, dtype=torch.float64, device=device)\n",
        "    x0 = torch.tensor([0.2], dtype=torch.float64, device=device)\n",
        "    x  = odeint(model, x0, t, method='radauIIA5_adaptive',\n",
        "                rtol=1e-6, atol=1e-9)\n",
        "    xT = x[-1, 0]\n",
        "    perf = (xT - 0.7)**2\n",
        "    reg  = 0.1 * model.p1**4 + 0.1 * torch.sin(4*model.p2)**2\n",
        "    return perf + reg                             # scalar\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Gradient-check utility\n",
        "# -------------------------------------------------------------------\n",
        "def gradient_check(model, eps=1e-4, tol=1e-2, device='cpu'):\n",
        "    \"\"\"Compare autograd gradient with central finite difference.\"\"\"\n",
        "    # 1) one forward pass builds the graph\n",
        "    loss0 = forward_sim_and_loss(model, device=device)\n",
        "    loss0.backward()                       # autograd grads now in .grad\n",
        "\n",
        "    print(f\"{'param':>6s} | {'autograd':>12s} | {'finite diff':>12s} | {'rel-err':>8s} | ok?\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    for name, p in model.named_parameters():\n",
        "        if p.grad is None or p.numel() != 1:\n",
        "            continue                       # skip non-scalar params\n",
        "\n",
        "        # 2) finite difference on *frozen* graph\n",
        "        with torch.no_grad():\n",
        "            p += eps\n",
        "        lp = forward_sim_and_loss(model, device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            p -= 2*eps\n",
        "        lm = forward_sim_and_loss(model, device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            p += eps                       # restore\n",
        "\n",
        "        fd = (lp - lm) / (2*eps)\n",
        "        ag = p.grad.item()\n",
        "        rel = abs(ag - fd.item()) / (abs(fd) + 1e-12)\n",
        "        print(f\"{name:6s} | {ag:+12.4e} | {fd.item():+12.4e} | {rel:8.1e} | \"\n",
        "              f\"{'✓' if rel < tol else '✗'}\")\n",
        "\n",
        "    # clear grads so optimiser can proceed afterwards\n",
        "    for p in model.parameters():\n",
        "        if p.grad is not None:\n",
        "            p.grad.zero_()\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Example usage\n",
        "# -------------------------------------------------------------------\n",
        "device = 'cpu'          # or 'cuda' if GPU available\n",
        "toy = ToyStiffODE().to(device)\n",
        "gradient_check(toy, eps=1e-4, tol=1e-2, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZnDu8J-yEa8",
        "outputId": "d0f8d991-747d-47d2-8f94-7f22e9b5f323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " param |     autograd |  finite diff |  rel-err | ok?\n",
            "------------------------------------------------------------\n",
            "p1     |  -3.1772e-01 |  -3.1780e-01 |  2.3e-04 | ✓\n",
            "p2     |  -2.7346e-01 |  -2.7397e-01 |  1.9e-03 | ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "uG6Sm9bigAFz",
        "outputId": "56cabb0f-f448-4933-c7b9-f9c833ab3169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 00 | loss=  1.0013 | p1      | p2     \n",
            "epoch 01 | loss=  0.9661 | p1      | p2     \n",
            "epoch 02 | loss=  0.9092 | p1      | p2     \n",
            "epoch 03 | loss=  0.7925 | p1      | p2     \n",
            "epoch 04 | loss=  0.4300 | p1      | p2     \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "underflow in dt 1.0313615728434908e-16",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9b2fc74529a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-9b2fc74529a7>\u001b[0m in \u001b[0;36msimulate_and_loss\u001b[0;34m(model, T)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dopri5'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape [steps,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mxT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mx_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnext_t\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_num_steps exceeded ({}>={})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adaptive_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0mn_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_interp_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m#                      Assertions                      #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'underflow in dt {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'non-finite values in state `y`: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: underflow in dt 1.0313615728434908e-16"
          ]
        }
      ],
      "source": [
        "############################################################\n",
        "# 0.  imports\n",
        "############################################################\n",
        "import torch, math, numpy as np\n",
        "from torchdiffeq import odeint\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device, dtype = 'cpu', torch.float64       # works on GPU too\n",
        "\n",
        "############################################################\n",
        "# 1.  the toy ODE as a nn.Module so parameters require_grad\n",
        "############################################################\n",
        "class ToyODE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.p1 = torch.nn.Parameter(torch.tensor(+0.8, dtype=dtype))   # start on left flank\n",
        "        self.p2 = torch.nn.Parameter(torch.tensor(+1.5, dtype=dtype))   # off a sine valley\n",
        "    def forward(self, t, x):\n",
        "        return self.p1 * x**3 - x + self.p2 * torch.sin(3*t)\n",
        "\n",
        "############################################################\n",
        "# 2.  objective  L(p1,p2)\n",
        "############################################################\n",
        "def simulate_and_loss(model, T=2.0):\n",
        "    t = torch.linspace(0.0, T, 201, dtype=dtype, device=device)\n",
        "    x0 = torch.tensor([0.2], dtype=dtype, device=device)\n",
        "    x  = odeint(model, x0, t, method='dopri5')  # shape [steps,1]\n",
        "    xT = x[-1,0]\n",
        "    x_star = torch.tensor(0.7, dtype=dtype, device=device)\n",
        "    perf = (xT - x_star)**2\n",
        "    reg  = 0.1*model.p1**4 + 0.1*torch.sin(4*model.p2)**2\n",
        "    return (perf + reg), perf.detach(), reg.detach()\n",
        "\n",
        "############################################################\n",
        "# 3.  optimisation loop with sign logging\n",
        "############################################################\n",
        "model  = ToyODE().to(device)\n",
        "opt    = torch.optim.Adam(model.parameters(), lr=0.05, betas=(0.5,0.999))\n",
        "\n",
        "prev_sign = {n: None for n,_ in model.named_parameters()}\n",
        "\n",
        "for epoch in range(25):\n",
        "    opt.zero_grad()\n",
        "    loss, perf, reg = simulate_and_loss(model)\n",
        "    loss.backward()\n",
        "\n",
        "    # ---- print sign-flip information\n",
        "    msgs = []\n",
        "    for n,p in model.named_parameters():\n",
        "        s = torch.sign(p.grad.detach()).item()\n",
        "        flip = (prev_sign[n] is not None) and (s != prev_sign[n])\n",
        "        prev_sign[n] = s\n",
        "        msgs.append(f\"{n} {'flip' if flip else '    '}\")\n",
        "\n",
        "    print(f\"epoch {epoch:02d} | loss={loss.item():8.4f} | \"\n",
        "          f\"{' | '.join(msgs)}\")\n",
        "\n",
        "    opt.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "FEOztMfj9hLm",
        "outputId": "360b991b-4a6d-41af-adf3-fb74c631cafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch |       loss |  grad-p1  flip? |  grad-p2  flip? |  fd-match?\n",
            "    0 |     1.0013 | -3.18e-01   | -2.73e-01   | ✓\n",
            "    1 |     0.9661 | -4.76e-01   | -3.74e-01   | ✗\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1f3746b747c9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprev_sign\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mfd\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mfinite_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# uses same radau + frozen graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mrel\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mfd_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfd_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# ~1 % tolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1f3746b747c9>\u001b[0m in \u001b[0;36mfinite_diff\u001b[0;34m(model, param, eps)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_sim_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1f3746b747c9>\u001b[0m in \u001b[0;36mforward_sim_and_loss\u001b[0;34m(model, T)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mt_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx0\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     x      = odeint(model, x0, t_grid,\n\u001b[0m\u001b[1;32m     28\u001b[0m                     method='radauIIA5_adaptive', rtol=1e-6, atol=1e-9)\n\u001b[1;32m     29\u001b[0m     \u001b[0mxT\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnext_t\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_num_steps exceeded ({}>={})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adaptive_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0mn_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_interp_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/adaptive_radau.py\u001b[0m in \u001b[0;36m_adaptive_step\u001b[0;34m(self, st)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# (1) explicit predictor (order p-1, cheap)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         y_pred, f_pred, _, k_pred = _runge_kutta_step(\n\u001b[0m\u001b[1;32m     42\u001b[0m             self.func, y0, f0, t0, dt, t1, tableau=self.tableau)\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mperturb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbeta_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UncheckedAssign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# Do nothing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# =========================================================\n",
        "# 0.  Imports & configuration\n",
        "# =========================================================\n",
        "import torch, math\n",
        "from torchdiffeq import odeint\n",
        "torch.manual_seed(0)\n",
        "device, dtype = 'cpu', torch.float64        # switch to 'cuda' if you like\n",
        "\n",
        "# =========================================================\n",
        "# 1.  A stiff(ish) scalar ODE with two learnable parameters\n",
        "#     dx/dt = p1 * x^3 - x + p2 * sin(3t)\n",
        "# =========================================================\n",
        "class ToyStiffODE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.p1 = torch.nn.Parameter(torch.tensor(+0.8, dtype=dtype))\n",
        "        self.p2 = torch.nn.Parameter(torch.tensor(+1.5, dtype=dtype))\n",
        "    def forward(self, t, x):\n",
        "        return self.p1 * x**3 - x + self.p2 * torch.sin(3*t)\n",
        "\n",
        "# =========================================================\n",
        "# 2.  Loss = squared terminal error  +  non-convex penalty\n",
        "# =========================================================\n",
        "def forward_sim_and_loss(model, T=2.0):\n",
        "    t_grid = torch.linspace(0.0, T, 401, dtype=dtype, device=device)\n",
        "    x0     = torch.tensor([0.2], dtype=dtype, device=device)\n",
        "    x      = odeint(model, x0, t_grid,\n",
        "                    method='radauIIA5_adaptive', rtol=1e-6, atol=1e-9)\n",
        "    xT     = x[-1, 0]\n",
        "    perf   = (xT - 0.7)**2\n",
        "    reg    = 0.1 * model.p1.pow(4) + 0.1 * torch.sin(4.0 * model.p2).pow(2)\n",
        "    return perf + reg, perf.detach(), reg.detach()\n",
        "\n",
        "# =========================================================\n",
        "# 3.  Helper: central finite difference on *frozen graph*\n",
        "# =========================================================\n",
        "def finite_diff(model, param, eps=1e-4):\n",
        "    theta = param.data\n",
        "    loss0, *_ = forward_sim_and_loss(model)      # build graph once\n",
        "\n",
        "    with torch.no_grad():\n",
        "        theta += eps\n",
        "    lp, *_ = forward_sim_and_loss(model)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        theta -= 2*eps\n",
        "    lm, *_ = forward_sim_and_loss(model)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        theta += eps                            # restore\n",
        "    return (lp - lm) / (2*eps)\n",
        "\n",
        "# =========================================================\n",
        "# 4.  Optimisation loop with gradient-sign tracker\n",
        "# =========================================================\n",
        "model = ToyStiffODE().to(device)\n",
        "opt   = torch.optim.Adam(model.parameters(), lr=0.05, betas=(0.5, 0.999))\n",
        "\n",
        "prev_sign = {}\n",
        "\n",
        "print(f\"{'epoch':>5s} | {'loss':>10s} |  grad-p1  flip? |  grad-p2  flip? |  fd-match?\")\n",
        "for epoch in range(15):\n",
        "    opt.zero_grad()\n",
        "    loss, perf, reg = forward_sim_and_loss(model)\n",
        "    loss.backward()\n",
        "\n",
        "    # ----- sign & FD diagnostics ------------------------------------\n",
        "    row = [f\"{epoch:5d}\", f\"{loss.item():10.4f}\"]\n",
        "\n",
        "    fd_ok = True\n",
        "    for name, p in model.named_parameters():\n",
        "        g     = p.grad.detach().clone()\n",
        "        sgn   = int(torch.sign(g).item())\n",
        "        flip  = (name in prev_sign) and (prev_sign[name] != sgn)\n",
        "        prev_sign[name] = sgn\n",
        "\n",
        "        fd    = finite_diff(model, p)           # uses same radau + frozen graph\n",
        "        rel   = (g - fd).abs() / (fd.abs() + 1e-12)\n",
        "        fd_ok = fd_ok and (rel.item() < 1e-2)   # ~1 % tolerance\n",
        "\n",
        "        row.append(f\"{g.item():+9.2e} {'✓' if flip else ' '}\")\n",
        "    row.append(\"✓\" if fd_ok else \"✗\")\n",
        "    print(\" | \".join(row))\n",
        "\n",
        "    opt.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVaTopYAClVQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "29fb762b-7d50-4953-c6cb-314158f1d22a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c7308ae6ffc8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c7308ae6ffc8>\u001b[0m in \u001b[0;36msimulate_and_loss\u001b[0;34m(model, T)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'radau'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape [steps,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mxT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mx_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnext_t\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_num_steps exceeded ({}>={})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adaptive_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mn_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_interp_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# trigger both. (i.e. interleaving them would be wrong.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_runge_kutta_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtableau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;31m# dtypes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# y1.dtype == self.y0.dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtableau\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UncheckedAssign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtableau\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableau\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malpha_i\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# Always step to perturbing just before the end time, in case of discontinuities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1162\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             )\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "############################################################\n",
        "# 0.  imports\n",
        "############################################################\n",
        "import torch, math, numpy as np\n",
        "from torchdiffeq import odeint\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device, dtype = 'cpu', torch.float64       # works on GPU too\n",
        "\n",
        "############################################################\n",
        "# 1.  the toy ODE as a nn.Module so parameters require_grad\n",
        "############################################################\n",
        "class ToyODE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.p1 = torch.nn.Parameter(torch.tensor(+0.8, dtype=dtype))   # start on left flank\n",
        "        self.p2 = torch.nn.Parameter(torch.tensor(+1.5, dtype=dtype))   # off a sine valley\n",
        "    def forward(self, t, x):\n",
        "        return self.p1 * x - x + self.p2 * torch.sin(3*t)\n",
        "\n",
        "############################################################\n",
        "# 2.  objective  L(p1,p2)\n",
        "############################################################\n",
        "def simulate_and_loss(model, T=2.0):\n",
        "    t = torch.linspace(0.0, T, 201, dtype=dtype, device=device)\n",
        "    x0 = torch.tensor([0.2], dtype=dtype, device=device)\n",
        "    x  = odeint(model, x0, t, method='radau')  # shape [steps,1]\n",
        "    xT = x[-1,0]\n",
        "    x_star = torch.tensor(0.7, dtype=dtype, device=device)\n",
        "    perf = (xT - x_star)**2\n",
        "    reg  = 0.1*model.p1**4 + 0.1*torch.sin(4*model.p2)**2\n",
        "    return (perf + reg), perf.detach(), reg.detach()\n",
        "\n",
        "############################################################\n",
        "# 3.  optimisation loop with sign logging\n",
        "############################################################\n",
        "model  = ToyODE().to(device)\n",
        "opt    = torch.optim.Adam(model.parameters(), lr=0.05, betas=(0.5,0.999))\n",
        "\n",
        "prev_sign = {n: None for n,_ in model.named_parameters()}\n",
        "\n",
        "for epoch in range(25):\n",
        "    opt.zero_grad()\n",
        "    loss, perf, reg = simulate_and_loss(model)\n",
        "    loss.backward()\n",
        "\n",
        "    # ---- print sign-flip information\n",
        "    msgs = []\n",
        "    for n,p in model.named_parameters():\n",
        "        s = torch.sign(p.grad.detach()).item()\n",
        "        flip = (prev_sign[n] is not None) and (s != prev_sign[n])\n",
        "        prev_sign[n] = s\n",
        "        msgs.append(f\"{n} {'flip' if flip else '    '}\")\n",
        "\n",
        "    print(f\"epoch {epoch:02d} | loss={loss.item():8.4f} | \"\n",
        "          f\"{' | '.join(msgs)}\")\n",
        "\n",
        "    opt.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUqfy3lkCi26",
        "outputId": "75764d4b-f786-4a8f-c258-265c5eba5678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-ef5465265c34>:717: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.original_rL           = torch.tensor(self.network.rL.clone().detach(),dtype=self.dtype, device=self.device)\n"
          ]
        }
      ],
      "source": [
        "    sim = MultiConverterSimulation(device=device, dtype=dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuhOypzFFLlK"
      },
      "outputs": [],
      "source": [
        "def perf_only_gradients(sim):\n",
        "    t, sol = sim.run_simulation_for_scenario(\"load_change\")\n",
        "\n",
        "    # plain performance loss (no hinge, no λ)\n",
        "    loss_perf = sim.compute_loss(t, sol)        # your voltage-error fn\n",
        "    sim.zero_grad()\n",
        "    loss_perf.backward()\n",
        "\n",
        "    grads = {n: p.grad.detach().clone()\n",
        "             for n,p in sim.named_parameters() if p.grad is not None}\n",
        "\n",
        "    # quick print\n",
        "    for n,g in grads.items():\n",
        "        print(f\"{n:7s}  g_perf={g.item():+9.2e}\")\n",
        "    return grads, t, sol\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_perf, t_vec, sol = perf_only_gradients(sim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erDsV8GyN1Sg",
        "outputId": "ec90b602-65a8-4a29-fc69-3a570f5b4acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Calculating default equilibrium target …\n",
            "Converged with trf\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 88.25816872 -84.89081752  91.7943647  -67.20780351  88.19850704\n",
            " -85.09822197]…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/rk_common.py:468: UserWarning: Functional iteration did not converge. Solution may be incorrect.\n",
            "  warnings.warn('Functional iteration did not converge. Solution may be incorrect.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eta      g_perf=+6.00e+91\n",
            "eta_a    g_perf=+3.29e+91\n",
            "Kp_v     g_perf=-3.41e+93\n",
            "Ki_v     g_perf=+2.69e+89\n",
            "Kp_f     g_perf=-6.65e+92\n",
            "Ki_f     g_perf=+1.54e+88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "# 0. configuration\n",
        "#######################################################################\n",
        "EPS = 1e-6              # parameter perturbation\n",
        "sim = MultiConverterSimulation(device=device, dtype=dtype)\n",
        "\n",
        "device = next(sim.parameters()).device\n",
        "\n",
        "#######################################################################\n",
        "# 1. run a baseline forward pass (build graph once)\n",
        "#######################################################################\n",
        "t0, sol0 = sim.run_simulation_for_scenario(\"load_change\")\n",
        "loss0, *_ = sim.compute_lagrangian_loss(t0, sol0)      # full loss or perf-only\n",
        "sim.zero_grad()\n",
        "loss0.backward()\n",
        "\n",
        "print(f\"{'param':7s} | autograd⋅Δ |  Δloss  | ratio \")\n",
        "print(\"-\"*46)\n",
        "\n",
        "#######################################################################\n",
        "# 2. loop over each scalar learnable parameter\n",
        "#######################################################################\n",
        "for name, p in sim.named_parameters():\n",
        "\n",
        "    if p.grad is None or p.numel() != 1:\n",
        "        continue\n",
        "\n",
        "    # ----- predicted change from gradient ----------------------------\n",
        "    grad_dir = p.grad.item()\n",
        "    pred_dL  = grad_dir * EPS          # first-order Taylor\n",
        "\n",
        "    # ----- finite-difference loss change -----------------------------\n",
        "    with torch.no_grad():\n",
        "        p += EPS\n",
        "    t1, sol1 = sim.run_simulation_for_scenario(\"load_change\")\n",
        "    loss1, *_ = sim.compute_lagrangian_loss(t1, sol1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        p -= EPS                       # restore\n",
        "\n",
        "    fd_dL = (loss1 - loss0).item()\n",
        "\n",
        "    # ----- ratio ------------------------------------------------------\n",
        "    ratio = float('inf') if pred_dL == 0 else fd_dL / pred_dL\n",
        "\n",
        "    print(f\"{name:7s} | {pred_dL:+10.3e} | {fd_dL:+10.3e} | {ratio:6.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_hYisEHZGzs",
        "outputId": "8c01d255-bb47-4ff3-e9aa-7968b9c4aa77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-fde7fd890164>:717: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.original_rL           = torch.tensor(self.network.rL.clone().detach(),dtype=self.dtype, device=self.device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Calculating default equilibrium target …\n",
            "Converged with trf\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 88.25816872 -84.89081752  91.7943647  -67.20780351  88.19850704\n",
            " -85.09822197]…\n",
            "param   | autograd⋅Δ |  Δloss  | ratio \n",
            "----------------------------------------------\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ -55.71470797 -109.04344856  -37.77650315 -107.31292084  -55.95357677\n",
            " -109.04679804]…\n",
            "eta     | +7.603e-06 | +7.605e-06 |   1.00\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-120.4998614    21.77991519 -113.65305148    5.10992888 -120.57229558\n",
            "   22.00793585]…\n",
            "eta_a   | -4.150e-09 | -2.481e-09 |   0.60\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-14.1508982  121.63193322 -28.11423174 110.23936366 -13.95364957\n",
            " 121.76752305]…\n",
            "Kp_v    | +5.571e-10 | +9.375e-10 |   1.68\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [112.2831968   48.8575349   97.3271241   58.91144464 112.47022084\n",
            "  48.70814579]…\n",
            "Ki_v    | -6.119e-11 | -1.356e-09 |  22.17\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-1.5e-323  2.5e-323  9.9e-324  4.9e-324 -2.0e-323  2.5e-323]…\n",
            "Kp_f    | +7.730e-11 | +4.091e-10 |   5.29\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 0.0e+000 -2.5e-323  4.9e-324  0.0e+000 -4.9e-324  2.0e-323]…\n",
            "Ki_f    | -2.358e-12 | +1.361e-08 | -5772.77\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 0.0e+000  0.0e+000  0.0e+000  2.0e-323  0.0e+000 -1.5e-323]…\n",
            "lambda_cond4 | +6.603e-06 | +6.603e-06 |   1.00\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 0.e+000 -5.e-324  0.e+000  5.e-324  0.e+000 -5.e-324]…\n",
            "lambda_cond5 | +0.000e+00 | -3.553e-15 |    inf\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-4.9e-324 -4.9e-324 -9.9e-324  0.0e+000  1.5e-323  9.9e-324]…\n",
            "lambda_cond6 | +0.000e+00 | -3.553e-15 |    inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad = pred_dL / EPS        # true ∂L/∂θ\n",
        "print(f\"{name}  grad = {grad:+.3e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8Kt0OQHVe7n",
        "outputId": "de891a57-b86a-44c8-88a1-ead9bb797c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lambda_cond6  grad = +0.000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "HQsLvjAQyAI4",
        "outputId": "04b9bc20-5596-40f6-8359-3a70b8d7765c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# prompt: plot t_vec and sol noting they are torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(t_vec.cpu().detach().numpy(), sol.cpu().detach().numpy())\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Solution\")\n",
        "plt.title(\"Plot of Solution vs. Time\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aywhCp_iDfx9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming t_vec, sol, and sol1 are your data\n",
        "# Get the number of columns from the solution data\n",
        "num_columns = sol.shape[1]\n",
        "\n",
        "# Create subplots - adjust the figure size based on number of columns\n",
        "# For many columns, a grid layout might be better\n",
        "rows = min(8, num_columns)  # Maximum 5 rows, then create multiple columns\n",
        "cols = int(np.ceil(num_columns / rows))\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 3*rows), sharex=True)\n",
        "\n",
        "# Flatten the axes array for easier indexing\n",
        "axes = axes.flatten() if num_columns > 1 else [axes]\n",
        "\n",
        "# Convert tensors to numpy once to avoid repetition\n",
        "t_numpy = t_vec.cpu().detach().numpy()\n",
        "sol_numpy = sol.cpu().detach().numpy()\n",
        "sol1_numpy = sol1.cpu().detach().numpy()\n",
        "\n",
        "# Loop through the columns and plot\n",
        "for i in range(num_columns):\n",
        "    # Plot both sol and sol1 on the same subplot\n",
        "    axes[i].plot(t_numpy, sol_numpy[:, i], label='sol')\n",
        "    axes[i].plot(t_numpy, sol1_numpy[:, i], label='sol1')\n",
        "\n",
        "    # Add labels\n",
        "    axes[i].set_ylabel(f\"Column {i}\")\n",
        "    axes[i].set_title(f\"Column {i}\")\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True)\n",
        "\n",
        "# Hide any unused subplots\n",
        "for i in range(num_columns, len(axes)):\n",
        "    axes[i].set_visible(False)\n",
        "\n",
        "# Add a common x-label to the figure\n",
        "fig.text(0.5, 0.04, \"Time\", ha='center', va='center', fontsize=12)\n",
        "\n",
        "# Add a title to the overall figure\n",
        "fig.suptitle(\"Plot of Solutions vs. Time for All Columns\", fontsize=16)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.92, bottom=0.08)  # Make room for suptitle and xlabel\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPGJGZ3UyPP3"
      },
      "outputs": [],
      "source": [
        "plt.plot(t_vec.cpu().detach().numpy(), sol[:,0+6+6].cpu().detach().numpy())\n",
        "plt.plot(t_vec.cpu().detach().numpy(), sol1[:,0+6+6].cpu().detach().numpy())\n",
        "\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Solution\")\n",
        "plt.title(\"Plot of Solution vs. Time\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhfBnwIlQAP6",
        "outputId": "5e427940-f7e2-4aa7-92a6-3d0694bb6eec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Setpoints(v_star=tensor([120., 120., 120.], device='cuda:0', dtype=torch.float64), p_star=tensor([43.2000, 41.0000, 41.0000], device='cuda:0', dtype=torch.float64), q_star=tensor([-0.9000,  0.5000, -0.5000], device='cuda:0', dtype=torch.float64), theta_star=tensor([0., 0., 0.], device='cuda:0', dtype=torch.float64))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simo.converter.setpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X47wSVq1y3Rr"
      },
      "outputs": [],
      "source": [
        "plt.plot(t_vec.cpu().detach().numpy(), sol[:,0+6+6].cpu().detach().numpy())\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Solution\")\n",
        "plt.title(\"Plot of Solution vs. Time\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0X_w-thy0nS"
      },
      "outputs": [],
      "source": [
        "    sim = MultiConverterSimulation(device=device, dtype=dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IDsxsNCyoQc",
        "outputId": "ab0171ba-fe28-48b1-de56-7a46bc654730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 5.7500 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [116.50104219 -14.81473862 105.72316683 -58.36056449 105.7276233\n",
            " -58.35004685]…\n"
          ]
        }
      ],
      "source": [
        "            t_vec, sol = sim.run_simulation_for_scenario(\"load_change\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6QvyLsdy0_2"
      },
      "outputs": [],
      "source": [
        "a=12\n",
        "q=torch.sqrt(sol[:,a]**2+sol[:,a+1]**2)\n",
        "#q2=torch.sqrt(sol1[:,a]**2+sol1[:,a+1]**2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "H2-XMmZbQS04",
        "outputId": "f212753a-9048-4603-9fa2-c691143ea5f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6649646750>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(q.cpu().detach().numpy())\n",
        "#plt.plot(q2.cpu().detach().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTU95V1DQcT4"
      },
      "outputs": [],
      "source": [
        "plt.plot(q2.cpu().detach().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skdO6FEEUm3X"
      },
      "outputs": [],
      "source": [
        "sim.compute_equilibrium_point()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18VB4LpqUwb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd37fa60-fa4b-45d2-e91d-a6c49e66dd61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(119.8126, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "q[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lsX1etYUwuC"
      },
      "outputs": [],
      "source": [
        "target_equilibrium = sim.scenario_equilibrium_targets.get(sim.scenario)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPAFEIgEV6-N"
      },
      "outputs": [],
      "source": [
        "target_equilibrium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVXJm7mKV75o"
      },
      "outputs": [],
      "source": [
        "sim.network.rL=115"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBGUo9RIWBa-",
        "outputId": "ee46be0e-2b1b-46a0-9815-8156800eb826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converged with trf\n"
          ]
        }
      ],
      "source": [
        "a=sim.compute_equilibrium_point()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id_eyAOUUnlq",
        "outputId": "abbd870b-5579-4c14-c81e-8f242b7e372d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([36])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq9n2GOYU2iV",
        "outputId": "b2490b30-b4dc-434d-81e9-1957d249ff5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 88.25816872 -84.89081752  91.7943647  -67.20780351  88.19850704\n",
            " -85.09822197]…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchdiffeq/_impl/misc.py:15: UserWarning: AdaptiveRadauIIA5: Unexpected arguments {'dt_min': 1e-08}\n",
            "  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "param   | autograd⋅Δ |  Δloss  | ratio \n",
            "----------------------------------------------\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ -55.71470797 -109.04344856  -37.77650315 -107.31292084  -55.95357677\n",
            " -109.04679804]…\n",
            "eta     | +4.789e+00 | -1.065e+04 | -2224.59\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-120.4998614    21.77991519 -113.65305148    5.10992888 -120.57229558\n",
            "   22.00793585]…\n",
            "eta_a   | -1.729e+01 | +5.005e+04 | -2894.68\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-14.1508982  121.63193322 -28.11423174 110.23936366 -13.95364957\n",
            " 121.76752305]…\n",
            "Kp_v    | +1.539e+03 | +1.416e+04 |   9.21\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with trf\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [112.2831968   48.8575349   97.3271241   58.91144464 112.47022084\n",
            "  48.70814579]…\n",
            "Ki_v    | +1.520e+00 | -1.066e+04 | -7012.58\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-1.5e-323  2.5e-323  9.9e-324  4.9e-324 -2.0e-323  2.5e-323]…\n",
            "Kp_f    | +1.039e+02 | +6.389e+05 | 6150.44\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 0.0e+000 -2.5e-323  4.9e-324  0.0e+000 -4.9e-324  2.0e-323]…\n",
            "Ki_f    | -6.169e-02 | +1.425e+04 | -231047.85\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 0.0e+000  0.0e+000  0.0e+000  2.0e-323  0.0e+000 -1.5e-323]…\n",
            "lambda_cond4 | +6.603e-06 | +6.603e-06 |   1.00\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [ 0.e+000 -5.e-324  0.e+000  5.e-324  0.e+000 -5.e-324]…\n",
            "lambda_cond5 | +0.000e+00 | +0.000e+00 |    inf\n",
            "\n",
            "--- Setting up scenario: load_change ---\n",
            "Scenario 'load_change': rL = 11.5000 Ω\n",
            "Converged with fsolve\n",
            "  … new equilibrium accepted (‖F‖<1e‑4).\n",
            "Target equilibrium used by LOSS: [-4.9e-324 -4.9e-324 -9.9e-324  0.0e+000  1.5e-323  9.9e-324]…\n",
            "lambda_cond6 | +0.000e+00 | +0.000e+00 |    inf\n"
          ]
        }
      ],
      "source": [
        "#######################################################################\n",
        "# 0. configuration\n",
        "#######################################################################\n",
        "EPS = 1e-6               # parameter perturbation\n",
        "device = next(sim.parameters()).device\n",
        "\n",
        "#######################################################################\n",
        "# 1. run a baseline forward pass (build graph once)\n",
        "#######################################################################\n",
        "t0, sol0 = sim.run_simulation_for_scenario(\"load_change\")\n",
        "loss0, *_ = sim.compute_lagrangian_loss(t0, sol0)      # full loss or perf-only\n",
        "sim.zero_grad()\n",
        "loss0.backward()\n",
        "\n",
        "print(f\"{'param':7s} | autograd⋅Δ |  Δloss  | ratio \")\n",
        "print(\"-\"*46)\n",
        "\n",
        "#######################################################################\n",
        "# 2. loop over each scalar learnable parameter\n",
        "#######################################################################\n",
        "for name, p in sim.named_parameters():\n",
        "\n",
        "    if p.grad is None or p.numel() != 1:\n",
        "        continue\n",
        "\n",
        "    # ----- predicted change from gradient ----------------------------\n",
        "    grad_dir = p.grad.item()\n",
        "    pred_dL  = grad_dir * EPS          # first-order Taylor\n",
        "\n",
        "    # ----- finite-difference loss change -----------------------------\n",
        "    with torch.no_grad():\n",
        "        p += EPS\n",
        "    t1, sol1 = sim.run_simulation_for_scenario(\"load_change\")\n",
        "    loss1, *_ = sim.compute_lagrangian_loss(t1, sol1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        p -= EPS                       # restore\n",
        "\n",
        "    fd_dL = (loss1 - loss0).item()\n",
        "\n",
        "    # ----- ratio ------------------------------------------------------\n",
        "    ratio = float('inf') if pred_dL == 0 else fd_dL / pred_dL\n",
        "\n",
        "    print(f\"{name:7s} | {pred_dL:+10.3e} | {fd_dL:+10.3e} | {ratio:6.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsle6jzwU3tL"
      },
      "outputs": [],
      "source": [
        "\n",
        "        # Handle dimensions with/without line currents\n",
        "        Nc, Nt = sim.network.Nc, sim.network.Nt\n",
        "        n_conv, n_line = 2 * Nc, 2 * Nt\n",
        "\n",
        "        # Standardize state vector (remove line currents if present)\n",
        "        if sim.integrate_line_dynamics:\n",
        "            # Format: [vhat, i_line, v, zeta_v, i_f, zeta_f]\n",
        "            vhat_indices = slice(0, n_conv)\n",
        "            v_indices = slice(n_conv + n_line, 2*n_conv + n_line)\n",
        "        else:\n",
        "            # Format: [vhat, v, zeta_v, i_f, zeta_f]\n",
        "            vhat_indices = slice(0, n_conv)\n",
        "            v_indices = slice(n_conv, 2*n_conv)\n",
        "\n",
        "        # Extract voltage components\n",
        "        vhat_sol = sol[:, vhat_indices].reshape(-1, Nc, 2)  # reshape to [time, converters, αβ]\n",
        "        v_sol = sol[:, v_indices].reshape(-1, Nc, 2)       # reshape to [time, converters, αβ]\n",
        "\n",
        "        # Get voltage setpoints\n",
        "        v_star = sim.converter.setpoints.v_star  # [Nc]\n",
        "\n",
        "        # Compute voltage magnitudes\n",
        "        vhat_mag_sol = torch.norm(vhat_sol, dim=2)  # [time, Nc]\n",
        "        v_mag_sol = torch.norm(v_sol, dim=2)        # [time, Nc]\n",
        "\n",
        "        # Calculate magnitude deviations directly from v*\n",
        "        vhat_dev = (vhat_mag_sol - v_star.unsqueeze(0)) / v_star.unsqueeze(0)\n",
        "        v_dev = (v_mag_sol - v_star.unsqueeze(0)) / v_star.unsqueeze(0)\n",
        "\n",
        "        # Calculate L-infinity norm (maximum absolute deviation)\n",
        "        vhat_loss = torch.max(torch.abs(vhat_dev))\n",
        "        v_loss = torch.max(torch.abs(v_dev))\n",
        "\n",
        "        # Add peak oscillation measure for latter part of simulation\n",
        "        num_steps = sol.shape[0]\n",
        "        latter_half_idx = num_steps // 2\n",
        "        v_mag_latter = v_mag_sol[latter_half_idx:, :]\n",
        "\n",
        "        # Maximum peak-to-peak deviation for each converter in latter half\n",
        "        peak_to_peak = torch.max(v_mag_latter, dim=0)[0] - torch.min(v_mag_latter, dim=0)[0]\n",
        "        oscillation_penalty = torch.max(peak_to_peak) / torch.mean(v_star)\n",
        "\n",
        "        # Weight components (emphasize terminal voltage v over reference vhat)\n",
        "        total_loss = 3.0 * vhat_loss + 10.0 * v_loss\n",
        "\n",
        "        # Ensure we maintain gradients\n",
        "        if sol.requires_grad and not total_loss.requires_grad:\n",
        "            total_loss = total_loss + 0.0 * sol.sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSiiipFv_slu",
        "outputId": "090c31d9-6fd0-40c6-92ee-d7c1ba47b7ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "slice(0, 6, None)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vhat_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-0H_nva_w1U",
        "outputId": "0b71f6fb-3826-4c10-b39d-1d21895872e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0714, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.max(v_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oRovyP5_yP4",
        "outputId": "4933b36e-20fa-457c-9cba-fb191cc00222"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0742, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "RMW5c5PB_z6r",
        "outputId": "f169b4e8-2c3d-4cf6-8de7-1916676ef3e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7affc84e41d0>,\n",
              " <matplotlib.lines.Line2D at 0x7affc84e5850>]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(sol[:, v_indices][:,0:2].cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTf8fEEh_33O",
        "outputId": "917f1100-b46d-407e-ba8d-dba34e3d0520"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(128.5465859421806)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.max(sol[:, v_indices][:,0:2].cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9S1x9oUANN6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def differentiable_process_results(t_vec, sol, converter_indices=None, network_omega0=2*np.pi*60):\n",
        "    \"\"\"\n",
        "    Differentiable implementation of frequency calculation for dq-frame power systems.\n",
        "    Takes the same inputs as the original process_results method for drop-in compatibility.\n",
        "\n",
        "    Args:\n",
        "        t_vec: Time vector (numpy array or torch tensor)\n",
        "        sol: Solution array from ODE solver (numpy array or torch tensor)\n",
        "        converter_indices: Dict of indices for different state variables. If None, uses default indices.\n",
        "        network_omega0: Base angular frequency in rad/s (default: 2π × 60 Hz)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing results with torch tensors (compatible with autograd)\n",
        "    \"\"\"\n",
        "    # Convert inputs to PyTorch tensors if they aren't already\n",
        "    if not isinstance(t_vec, torch.Tensor):\n",
        "        t_vec = torch.tensor(t_vec, dtype=torch.float32)\n",
        "    if not isinstance(sol, torch.Tensor):\n",
        "        sol = torch.tensor(sol, dtype=torch.float32)\n",
        "\n",
        "    # Set up differentiable calculation parameters\n",
        "    omega_0 = network_omega0\n",
        "    f_0 = omega_0 / (2 * np.pi)\n",
        "\n",
        "    # Small constants for numerical stability\n",
        "    EPS = 1e-8\n",
        "\n",
        "    # Filtering parameters\n",
        "    alpha_initial = 0.05  # Strong filtering during startup\n",
        "    alpha_normal = 0.2    # Normal operation filtering\n",
        "    beta = 10.0           # Controls sharpness of soft transitions\n",
        "\n",
        "    # Setup indices if not provided\n",
        "    if converter_indices is None:\n",
        "        # Default indices based on the original implementation\n",
        "        Nc = 3  # Number of converters\n",
        "        Nt = 3  # Number of transmission lines\n",
        "        n_conv = 2*Nc\n",
        "        n_line = 2*Nt\n",
        "\n",
        "        # Define slicing indices\n",
        "        off_vhat = 0\n",
        "        off_iline = n_conv\n",
        "        off_v = off_iline + n_line\n",
        "        off_zeta_v = off_v + n_conv\n",
        "        off_if = off_zeta_v + n_conv\n",
        "        off_zeta_f = off_if + n_conv\n",
        "    else:\n",
        "        # Use provided indices\n",
        "        Nc = converter_indices['Nc']\n",
        "        off_vhat = converter_indices['off_vhat']\n",
        "        off_v = converter_indices['off_v']\n",
        "        off_if = converter_indices['off_if']\n",
        "\n",
        "    # Initialize output arrays - use PyTorch tensors for gradient tracking\n",
        "    nsamples = len(t_vec)\n",
        "    voltage_mag = torch.zeros((nsamples, Nc), dtype=torch.float32)\n",
        "    freq = torch.zeros((nsamples, Nc), dtype=torch.float32)\n",
        "    p_out = torch.zeros((nsamples, Nc), dtype=torch.float32)\n",
        "    q_out = torch.zeros((nsamples, Nc), dtype=torch.float32)\n",
        "\n",
        "    # Additional diagnostic arrays\n",
        "    vhat_freq = torch.zeros((nsamples, Nc), dtype=torch.float32)\n",
        "    v_freq = torch.zeros((nsamples, Nc), dtype=torch.float32)\n",
        "\n",
        "    # Initialize with base frequency\n",
        "    freq[:, :] = f_0\n",
        "    vhat_freq[:, :] = f_0\n",
        "    v_freq[:, :] = f_0\n",
        "\n",
        "    # Calculate startup cutoff for adaptive filtering\n",
        "    startup_cutoff = int(nsamples * 0.05)\n",
        "\n",
        "    # Define differentiable helper functions\n",
        "    def soft_sig(x):\n",
        "        \"\"\"Differentiable sigmoid activation\"\"\"\n",
        "        return torch.sigmoid(beta * x)\n",
        "\n",
        "    def soft_threshold(x, threshold):\n",
        "        \"\"\"Soft thresholding with gradients\"\"\"\n",
        "        return soft_sig(x - threshold)\n",
        "\n",
        "    def soft_clip(x, min_val, max_val):\n",
        "        \"\"\"Soft clipping function that maintains gradients\"\"\"\n",
        "        x_clipped_min = x + torch.log1p(torch.exp(beta * (min_val - x))) / beta\n",
        "        x_clipped = x_clipped_min - torch.log1p(torch.exp(beta * (x_clipped_min - max_val))) / beta\n",
        "        return x_clipped\n",
        "\n",
        "    def diff_phase_unwrap(phase_diff):\n",
        "        \"\"\"Differentiable phase unwrapping\"\"\"\n",
        "        wrapped_up = soft_sig(phase_diff - np.pi) * 2 * np.pi\n",
        "        wrapped_down = soft_sig(-phase_diff - np.pi) * 2 * np.pi\n",
        "        return phase_diff - wrapped_up + wrapped_down\n",
        "\n",
        "    def diff_validity_weight(freq_val, nominal, valid_range):\n",
        "        \"\"\"Differentiable validity weight calculation\"\"\"\n",
        "        deviation = torch.abs(freq_val - nominal)\n",
        "        return torch.exp(-beta * torch.relu(deviation - valid_range))\n",
        "\n",
        "    # Process each time step\n",
        "    prev_v = None\n",
        "    prev_vhat = None\n",
        "    prev_time = t_vec[0]\n",
        "    if len(t_vec) == 0:\n",
        "        # Handle empty input case if necessary, e.g., return empty results\n",
        "        return { # Return structure matching the normal output\n",
        "            'time': t_vec,\n",
        "            'voltage_mag': torch.zeros((0, Nc), dtype=torch.float32),\n",
        "            'frequency': torch.zeros((0, Nc), dtype=torch.float32),\n",
        "            'active_power': torch.zeros((0, Nc), dtype=torch.float32),\n",
        "            'reactive_power': torch.zeros((0, Nc), dtype=torch.float32),\n",
        "            'v_freq': torch.zeros((0, Nc), dtype=torch.float32),\n",
        "            'vhat_freq': torch.zeros((0, Nc), dtype=torch.float32)\n",
        "        }\n",
        "    prev_time = t_vec[0]\n",
        "\n",
        "    # Convert beta to a tensor for consistency if desired, though not strictly required here\n",
        "    # beta_t = torch.tensor(beta, dtype=torch.float32, device=t_vec.device) # Optional\n",
        "    # Or keep beta as float, PyTorch often handles float * tensor\n",
        "\n",
        "    for k in range(nsamples):\n",
        "        # Get current state\n",
        "        statek = sol[k, :]\n",
        "        vhat = statek[off_vhat:off_vhat + n_conv]\n",
        "        v_nodes = statek[off_v:off_v + n_conv]\n",
        "        i_f = statek[off_if:off_if + n_conv]\n",
        "\n",
        "        # Current time and delta time\n",
        "        current_time = t_vec[k]\n",
        "        # Ensure dt is a tensor, especially for the k=0 case\n",
        "        if k > 0:\n",
        "            # Difference between tensor elements results in a tensor scalar\n",
        "            dt = current_time - prev_time\n",
        "            # Add a small epsilon to dt only if it's exactly zero to avoid division by zero\n",
        "            # but retain gradients. Using torch.where is differentiable.\n",
        "            dt_safe = torch.where(dt <= 0, torch.tensor(EPS, dtype=dt.dtype, device=dt.device), dt)\n",
        "        else:\n",
        "            # Initialize dt as a tensor for the first step\n",
        "            dt = torch.tensor(0.0001, dtype=t_vec.dtype, device=t_vec.device) # Use input tensor's dtype and device\n",
        "            dt_safe = dt # Already non-zero\n",
        "\n",
        "        # Determine adaptive filtering strength - differentiable version\n",
        "        # --- FIX STARTS HERE ---\n",
        "        # Calculate time_progress as a float first\n",
        "        time_progress_float = float(k / startup_cutoff) if startup_cutoff > 0 else 1.0\n",
        "        # Convert time_progress to a tensor\n",
        "        time_progress = torch.tensor(time_progress_float, dtype=t_vec.dtype, device=t_vec.device)\n",
        "\n",
        "        # Now -beta * time_progress will result in a tensor because time_progress is a tensor\n",
        "        # (assuming beta remains a float, PyTorch handles float * tensor -> tensor)\n",
        "        # Or use beta_t if defined: startup_weight = torch.exp(-beta_t * time_progress)\n",
        "        startup_weight = torch.exp(-beta * time_progress)\n",
        "        # --- FIX ENDS HERE ---\n",
        "\n",
        "        alpha = alpha_initial * startup_weight + alpha_normal * (1 - startup_weight)\n",
        "\n",
        "        # Process each converter\n",
        "        for i in range(Nc):\n",
        "            idx_slice = slice(2*i, 2*(i+1))\n",
        "            v_dq = v_nodes[idx_slice]\n",
        "            vhat_dq = vhat[idx_slice]\n",
        "            i_f_dq = i_f[idx_slice]\n",
        "\n",
        "            # Calculate voltage magnitude (differentiable norm)\n",
        "            voltage_mag[k, i] = torch.sqrt(torch.sum(v_dq**2) + EPS)\n",
        "\n",
        "            # Calculate phase angles\n",
        "            v_phase_current = torch.atan2(v_dq[1], v_dq[0])\n",
        "            vhat_phase_current = torch.atan2(vhat_dq[1], vhat_dq[0])\n",
        "\n",
        "            # Only proceed with calculations if we have previous values\n",
        "            if k > 0:\n",
        "                # Voltage significance check - differentiable version\n",
        "                v_significant = soft_threshold(voltage_mag[k, i], 5.0)\n",
        "\n",
        "                # 1. vhat-based calculation\n",
        "                prev_vhat_dq = prev_vhat[idx_slice]\n",
        "                # Use dt_safe for division\n",
        "                dvhat_dt = (vhat_dq - prev_vhat_dq) / dt_safe\n",
        "\n",
        "                vhat_magnitude = torch.sqrt(torch.sum(vhat_dq**2) + EPS)\n",
        "                vhat_significant = soft_threshold(vhat_magnitude, 0.05) # Note: vhat_significant isn't used later?\n",
        "\n",
        "                # Cross product for rotation term\n",
        "                rotation_term = (vhat_dq[0] * dvhat_dt[1] - vhat_dq[1] * dvhat_dt[0])\n",
        "                # Normalize with safe division\n",
        "                norm_rotation = rotation_term / (vhat_magnitude**2 + EPS)\n",
        "                # Scale to frequency (assuming f_0 is already a tensor)\n",
        "                vhat_freq_val = f_0 + norm_rotation / (2 * torch.pi) # Use torch.pi\n",
        "                vhat_freq[k, i] = vhat_freq_val\n",
        "\n",
        "                # 2. Voltage phase change calculation\n",
        "                prev_v_phase = torch.atan2(prev_v[idx_slice][1], prev_v[idx_slice][0])\n",
        "                phase_diff = v_phase_current - prev_v_phase\n",
        "\n",
        "                # Differentiable phase unwrapping (use torch.pi)\n",
        "                phase_diff_unwrapped = diff_phase_unwrap(phase_diff) # Make sure diff_phase_unwrap uses torch.pi internally\n",
        "\n",
        "                # Convert to frequency (Use dt_safe)\n",
        "                v_freq_val = f_0 + phase_diff_unwrapped / (2 * torch.pi * dt_safe)\n",
        "                v_freq[k, i] = v_freq_val\n",
        "\n",
        "                # 3. Hybrid approach - differentiable version\n",
        "                # Validity weights (assuming diff_validity_weight handles tensors)\n",
        "                vhat_valid = diff_validity_weight(vhat_freq_val, f_0, 2.0)\n",
        "                v_valid = diff_validity_weight(v_freq_val, f_0, 2.0)\n",
        "\n",
        "                # Soft clipping (assuming soft_clip handles tensors)\n",
        "                v_freq_clipped = soft_clip(v_freq_val, f_0 - 1.0, f_0 + 1.0)\n",
        "                vhat_freq_clipped = soft_clip(vhat_freq_val, f_0 - 1.0, f_0 + 1.0)\n",
        "\n",
        "                # Normalized weights with soft transitions\n",
        "                total_weight = vhat_valid + v_valid + EPS\n",
        "                norm_vhat_weight = vhat_valid / total_weight\n",
        "                norm_v_weight = v_valid / total_weight\n",
        "\n",
        "                # Weight by startup vs. steady state\n",
        "                method_weight = startup_weight * norm_vhat_weight + (1 - startup_weight) * norm_v_weight\n",
        "\n",
        "                # Combine methods\n",
        "                combined_freq = method_weight * vhat_freq_clipped + (1 - method_weight) * v_freq_clipped\n",
        "\n",
        "                # Gate by voltage significance\n",
        "                inst_freq = v_significant * combined_freq + (1 - v_significant) * f_0\n",
        "\n",
        "                # Low-pass filter - differentiable (alpha is now tensor)\n",
        "                freq[k, i] = alpha * inst_freq + (1 - alpha) * freq[k-1, i]\n",
        "\n",
        "                # Calculate powers in dq-frame - differentiable\n",
        "                i_total = -i_f_dq\n",
        "                p_out[k, i] = v_dq[0] * i_total[0] + v_dq[1] * i_total[1]\n",
        "                q_out[k, i] = v_dq[1] * i_total[0] - v_dq[0] * i_total[1]\n",
        "            else:\n",
        "                # Initialize powers in first step (k=0)\n",
        "                # Frequencies are already initialized to f_0\n",
        "                i_total = -i_f_dq\n",
        "                p_out[k, i] = v_dq[0] * i_total[0] + v_dq[1] * i_total[1]\n",
        "                q_out[k, i] = v_dq[1] * i_total[0] - v_dq[0] * i_total[1]\n",
        "\n",
        "        # Store current values for next iteration\n",
        "        # Ensure cloning for tensors to avoid modifying previous state inadvertently if needed,\n",
        "        # though direct assignment might be fine if statek components are distinct slices.\n",
        "        # .clone().detach() if you don't want gradient history through prev_v/prev_vhat\n",
        "        prev_v = v_nodes.clone()\n",
        "        prev_vhat = vhat.clone()\n",
        "        prev_time = current_time\n",
        "\n",
        "    # No post-processing smoothing as it's not differentiable\n",
        "    # Instead, we rely on the low-pass filtering during the main calculation\n",
        "\n",
        "    return {\n",
        "        'time': t_vec,\n",
        "        'voltage_mag': voltage_mag,\n",
        "        'frequency': freq,\n",
        "        'active_power': p_out,\n",
        "        'reactive_power': q_out,\n",
        "        'v_freq': v_freq,\n",
        "        'vhat_freq': vhat_freq\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCSsrmyHsevG",
        "outputId": "013d6088-e926-48fb-dcdb-d3576f8a5e09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-26-2e782589ff30>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  results=differentiable_process_results(torch.tensor(t_vec), torch.tensor(sol), converter_indices=None, network_omega0=torch.tensor(2*np.pi*60))\n"
          ]
        }
      ],
      "source": [
        "results=differentiable_process_results(torch.tensor(t_vec), torch.tensor(sol), converter_indices=None, network_omega0=torch.tensor(2*np.pi*60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "JMg2CoP5sjL3",
        "outputId": "822a6e0b-5fbb-455c-b2ac-979c20c7f71d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(results['frequency']/60)\n",
        "plt.plot(resultso['frequency']/60)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzNjWA6zskbw"
      },
      "outputs": [],
      "source": [
        "resultso=results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0izMnl0DDuK",
        "outputId": "2ff0bb84-36f2-49eb-af62-416bc297f49f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([59.9337, 59.9337, 59.9337])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resultso['frequency'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EdmyravDO6S",
        "outputId": "32198d75-7d96-4417-95c1-5575c359bd7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([59.9587, 59.9587, 59.9587])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results['frequency'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMpR16ueDWEH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNTuVM6k79wX4/Z7aqENEUN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}